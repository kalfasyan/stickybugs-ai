{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecdc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c3800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available workers: 16\n"
     ]
    }
   ],
   "source": [
    "from datasets import InsectImgDataset\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "setting = 'photobox'\n",
    "if setting == 'photobox':\n",
    "    ext = '.png'\n",
    "elif setting == 'fuji':\n",
    "    ext = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5bdbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting info from filenames..: 100%|█| 30625/30625 [00:03<00:00, 8678\n"
     ]
    }
   ],
   "source": [
    "dfs = InsectImgDataset(ext=ext, setting=setting, directory=DATA_DIR)\n",
    "dfs.extract_df_info()\n",
    "df = dfs.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71459b84",
   "metadata": {},
   "source": [
    "# Creating train,val,test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854cb3e",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9db1aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>imgname</th>\n",
       "      <th>platename</th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>xtra</th>\n",
       "      <th>plate_idx</th>\n",
       "      <th>blur</th>\n",
       "      <th>...</th>\n",
       "      <th>plate_width</th>\n",
       "      <th>plate_height</th>\n",
       "      <th>platename_tmp</th>\n",
       "      <th>platename_ann</th>\n",
       "      <th>filepath_ann</th>\n",
       "      <th>yolo_x</th>\n",
       "      <th>yolo_y</th>\n",
       "      <th>yolo_width</th>\n",
       "      <th>yolo_height</th>\n",
       "      <th>txt_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_UNDISTORTED_herent_w28_1-90_4056x3040_202...</td>\n",
       "      <td>UNDISTORTED_herent_w28_1-90_4056x3040_20200703...</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w28</td>\n",
       "      <td>1-90</td>\n",
       "      <td>14131</td>\n",
       "      <td>42.842744</td>\n",
       "      <td>...</td>\n",
       "      <td>4015</td>\n",
       "      <td>2997</td>\n",
       "      <td>UNDISTORTED_herent_w28_1-90_4056x3040_20200703...</td>\n",
       "      <td>UNDISTORTED_herent_w28_1-90_4056x3040_20200703...</td>\n",
       "      <td>/home/kalfasyan/projects/stickybugs/processing...</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.735068</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>0.050050</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_herent_w27_1-30_4056x3040_23062020145640....</td>\n",
       "      <td>herent_w27_1-30_4056x3040_23062020145640.jpg</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w27</td>\n",
       "      <td>1-30</td>\n",
       "      <td>28190</td>\n",
       "      <td>25.307896</td>\n",
       "      <td>...</td>\n",
       "      <td>4056</td>\n",
       "      <td>3040</td>\n",
       "      <td>UNDISTORTED_herent_w27_1-30_4056x3040_23062020...</td>\n",
       "      <td>UNDISTORTED_herent_w27_1-30_4056x3040_23062020...</td>\n",
       "      <td>/home/kalfasyan/projects/stickybugs/processing...</td>\n",
       "      <td>0.567308</td>\n",
       "      <td>0.089309</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>0.049342</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_herent_w27_1-30_4056x3040_23062020145640....</td>\n",
       "      <td>herent_w27_1-30_4056x3040_23062020145640.jpg</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w27</td>\n",
       "      <td>1-30</td>\n",
       "      <td>28194</td>\n",
       "      <td>21.129386</td>\n",
       "      <td>...</td>\n",
       "      <td>4056</td>\n",
       "      <td>3040</td>\n",
       "      <td>UNDISTORTED_herent_w27_1-30_4056x3040_23062020...</td>\n",
       "      <td>UNDISTORTED_herent_w27_1-30_4056x3040_23062020...</td>\n",
       "      <td>/home/kalfasyan/projects/stickybugs/processing...</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>0.094901</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>0.049342</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_herent_w27_1-30_4056x3040_23062020145640....</td>\n",
       "      <td>herent_w27_1-30_4056x3040_23062020145640.jpg</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w27</td>\n",
       "      <td>1-30</td>\n",
       "      <td>28231</td>\n",
       "      <td>25.211150</td>\n",
       "      <td>...</td>\n",
       "      <td>4056</td>\n",
       "      <td>3040</td>\n",
       "      <td>UNDISTORTED_herent_w27_1-30_4056x3040_23062020...</td>\n",
       "      <td>UNDISTORTED_herent_w27_1-30_4056x3040_23062020...</td>\n",
       "      <td>/home/kalfasyan/projects/stickybugs/processing...</td>\n",
       "      <td>0.271203</td>\n",
       "      <td>0.208717</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>0.049342</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_herent_w27_1-30_4056x3040_23062020145640....</td>\n",
       "      <td>herent_w27_1-30_4056x3040_23062020145640.jpg</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w27</td>\n",
       "      <td>1-30</td>\n",
       "      <td>28233</td>\n",
       "      <td>34.813996</td>\n",
       "      <td>...</td>\n",
       "      <td>4056</td>\n",
       "      <td>3040</td>\n",
       "      <td>UNDISTORTED_herent_w27_1-30_4056x3040_23062020...</td>\n",
       "      <td>UNDISTORTED_herent_w27_1-30_4056x3040_23062020...</td>\n",
       "      <td>/home/kalfasyan/projects/stickybugs/processing...</td>\n",
       "      <td>0.417653</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>0.049342</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label  \\\n",
       "0  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "1  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "2  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "3  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "4  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "\n",
       "                                             imgname  \\\n",
       "0  2020_UNDISTORTED_herent_w28_1-90_4056x3040_202...   \n",
       "1  2020_herent_w27_1-30_4056x3040_23062020145640....   \n",
       "2  2020_herent_w27_1-30_4056x3040_23062020145640....   \n",
       "3  2020_herent_w27_1-30_4056x3040_23062020145640....   \n",
       "4  2020_herent_w27_1-30_4056x3040_23062020145640....   \n",
       "\n",
       "                                           platename  year location date  \\\n",
       "0  UNDISTORTED_herent_w28_1-90_4056x3040_20200703...  2020   herent  w28   \n",
       "1       herent_w27_1-30_4056x3040_23062020145640.jpg  2020   herent  w27   \n",
       "2       herent_w27_1-30_4056x3040_23062020145640.jpg  2020   herent  w27   \n",
       "3       herent_w27_1-30_4056x3040_23062020145640.jpg  2020   herent  w27   \n",
       "4       herent_w27_1-30_4056x3040_23062020145640.jpg  2020   herent  w27   \n",
       "\n",
       "   xtra  plate_idx       blur  ...  plate_width  plate_height  \\\n",
       "0  1-90      14131  42.842744  ...         4015          2997   \n",
       "1  1-30      28190  25.307896  ...         4056          3040   \n",
       "2  1-30      28194  21.129386  ...         4056          3040   \n",
       "3  1-30      28231  25.211150  ...         4056          3040   \n",
       "4  1-30      28233  34.813996  ...         4056          3040   \n",
       "\n",
       "                                       platename_tmp  \\\n",
       "0  UNDISTORTED_herent_w28_1-90_4056x3040_20200703...   \n",
       "1  UNDISTORTED_herent_w27_1-30_4056x3040_23062020...   \n",
       "2  UNDISTORTED_herent_w27_1-30_4056x3040_23062020...   \n",
       "3  UNDISTORTED_herent_w27_1-30_4056x3040_23062020...   \n",
       "4  UNDISTORTED_herent_w27_1-30_4056x3040_23062020...   \n",
       "\n",
       "                                       platename_ann  \\\n",
       "0  UNDISTORTED_herent_w28_1-90_4056x3040_20200703...   \n",
       "1  UNDISTORTED_herent_w27_1-30_4056x3040_23062020...   \n",
       "2  UNDISTORTED_herent_w27_1-30_4056x3040_23062020...   \n",
       "3  UNDISTORTED_herent_w27_1-30_4056x3040_23062020...   \n",
       "4  UNDISTORTED_herent_w27_1-30_4056x3040_23062020...   \n",
       "\n",
       "                                        filepath_ann    yolo_x    yolo_y  \\\n",
       "0  /home/kalfasyan/projects/stickybugs/processing...  0.109589  0.735068   \n",
       "1  /home/kalfasyan/projects/stickybugs/processing...  0.567308  0.089309   \n",
       "2  /home/kalfasyan/projects/stickybugs/processing...  0.043269  0.094901   \n",
       "3  /home/kalfasyan/projects/stickybugs/processing...  0.271203  0.208717   \n",
       "4  /home/kalfasyan/projects/stickybugs/processing...  0.417653  0.210526   \n",
       "\n",
       "   yolo_width  yolo_height  txt_label  \n",
       "0    0.037360     0.050050         bl  \n",
       "1    0.036982     0.049342         bl  \n",
       "2    0.036982     0.049342         bl  \n",
       "3    0.036982     0.049342         bl  \n",
       "4    0.036982     0.049342         bl  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre = pd.read_parquet(f\"{SAVE_DIR}/df_preparation_{setting}.parquet\")\n",
    "df = pd.merge(df,df_pre, on=['filename','label','platename','imgname','date','year','plate_idx','location','xtra'])\n",
    "df = df[df.knn_outlier==0]\n",
    "df = df[df.nb_contours>0]\n",
    "\n",
    "oe = OrdinalEncoder(cols=['label'],mapping=[{'col':'label', 'mapping':{'bl':0,'wswl':1,'sp':2,'t':3,'sw':4,'k':5,'m':6,'c':7,'v':8,'wmv':9,'wrl':10}}])\n",
    "df['txt_label'] = df['label']\n",
    "df['label'] = oe.fit_transform(df.label)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f746cd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_plates = train_test_split(df.platename.unique(), random_state=2022, test_size=0.2, shuffle=True)[1].tolist()\n",
    "testseries = pd.Series(test_plates)\n",
    "inds = testseries.apply(lambda x: 'wortel' in x)\n",
    "inds = testseries[inds].sample(11).index.values\n",
    "wortel_plates = testseries[inds].tolist()\n",
    "test_plates = testseries[testseries.apply(lambda x: x.split('_')[1] != 'wortel')].tolist() + wortel_plates\n",
    "\n",
    "df_trainval = df[~df.platename.isin(test_plates)]\n",
    "df_test = df[df.platename.isin(test_plates)]\n",
    "\n",
    "topclasses = df['label'].value_counts().head(11).index.tolist()\n",
    "\n",
    "df = df[df['label'].isin(topclasses)]\n",
    "df_trainval = df_trainval[df_trainval['label'].isin(topclasses)]\n",
    "df_test = df_test[df_test['label'].isin(topclasses)]\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  classes=np.unique(df['label'].tolist()), \n",
    "                                                  y=df['label'].tolist())\n",
    "\n",
    "class_weights = {np.unique(df['label'])[i]:class_weights[i] for i in range(len(class_weights))}\n",
    "df['weights'] = df['label'].map(class_weights)\n",
    "\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=0.18, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,3,1);df_train.txt_label.value_counts().plot(kind='barh');plt.title(f'train, {df_train.shape[0]}')\n",
    "plt.subplot(1,3,2);df_val.txt_label.value_counts().plot(kind='barh');plt.title(f'val, {df_val.shape[0]}')\n",
    "plt.subplot(1,3,3);df_test.txt_label.value_counts().plot(kind='barh');plt.title(f'test, {df_test.shape[0]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fdd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(df_train.filename.tolist()).intersection(df_test.filename.tolist())) == 0\n",
    "assert len(set(df_train.filename.tolist()).intersection(df_val.filename.tolist())) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af1bb016-ae27-456f-9cf1-294532cc7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(f\"{SAVE_DIR}/df_train_{setting}.parquet\")\n",
    "df_val.to_parquet(f\"{SAVE_DIR}/df_val_{setting}.parquet\")\n",
    "df_test.to_parquet(f\"{SAVE_DIR}/df_test_{setting}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c7b1e5-a740-4530-ae5f-24299737f2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     3535\n",
       "8     3154\n",
       "7     2785\n",
       "4     1777\n",
       "3     1558\n",
       "0     1440\n",
       "6      928\n",
       "5      646\n",
       "2      610\n",
       "10     590\n",
       "1      399\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3166c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating Pytorch Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61c23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_list_train = [\n",
    "#     A.SmallestMaxSize(max_size=150),\n",
    "#     A.Resize(height=150,width=150,p=1),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225], p=1, always_apply=True),\n",
    "    A.ShiftScaleRotate(shift_limit=0.01,rotate_limit=45, scale_limit=0, p=.5),\n",
    "    A.Rotate(limit=90, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    # A.RandomGamma(p=0.5),\n",
    "     A.RandomBrightnessContrast(p=0.2),\n",
    "     A.GaussianBlur(blur_limit=(3,3), p=0.1)\n",
    "]\n",
    "\n",
    "transforms_list_test = [\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                p=1, \n",
    "                always_apply=True)\n",
    "]\n",
    "\n",
    "train_dataset = InsectImgDataset(df=df_train.reset_index(drop=True), transform=A.Compose(transforms_list_train))\n",
    "valid_dataset = InsectImgDataset(df=df_val.reset_index(drop=True), transform=A.Compose(transforms_list_test))\n",
    "test_dataset = InsectImgDataset(df=df_test.reset_index(drop=True), transform=A.Compose(transforms_list_test))\n",
    "\n",
    "batch_size = 32\n",
    "batch_size_val = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size_val, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size_val, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "\n",
    "# plt.imshow(train_dataset[0][0]); plt.title(f\"Example train image, class:{train_dataset[0][1]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f75ae",
   "metadata": {},
   "source": [
    "#### Defining the model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234389bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5993df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: True\n"
     ]
    }
   ],
   "source": [
    "modelname = \"vgg16\"\n",
    "model = model_selector(modelname, pretrained=True)\n",
    "\n",
    "if modelname.startswith(\"dense\"):\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(num_ftrs,len(topclasses))\n",
    "if modelname.startswith(\"resn\"):\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs,len(topclasses))\n",
    "if modelname.startswith(\"efficient\"):\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_ftrs,len(topclasses))\n",
    "if modelname.startswith(\"vgg\"):\n",
    "    num_ftrs = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(num_ftrs, len(topclasses))\n",
    "    \n",
    "# Choosing whether to train on a gpu\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')# Number of gpus\n",
    "model = model.to('cuda', dtype=torch.float)\n",
    "\n",
    "num_epochs = 40\n",
    "\n",
    "class_sample_count = np.unique(df_train.label, return_counts=True)[1]\n",
    "weight = 1. / class_sample_count  \n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=.25, weight=torch.Tensor(weight).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "276ad0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=.001)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, cycle_momentum=False, mode=\"triangular2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e6d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, eps=1e-3, amsgrad=True)\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, cycle_momentum=False, mode=\"triangular2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cc53eb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ace6f25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:46<00:00,  5.13it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:11<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_acc: 51.2% loss: 2.4117994,  val_loss: 2.6146784 val_acc: 63.7%\n",
      "Validation accuracy improved from 0.00 to 63.66. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.30it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_acc: 66.9% loss: 1.9109842,  val_loss: 2.1956840 val_acc: 73.9%\n",
      "Validation accuracy improved from 63.66 to 73.93. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.31it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_acc: 71.0% loss: 1.3972597,  val_loss: 2.5510364 val_acc: 69.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.30it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_acc: 73.7% loss: 1.8434454,  val_loss: 2.2948723 val_acc: 78.4%\n",
      "Validation accuracy improved from 73.93 to 78.43. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.31it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_acc: 75.1% loss: 1.4498599,  val_loss: 2.3379376 val_acc: 79.9%\n",
      "Validation accuracy improved from 78.43 to 79.92. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.31it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_acc: 76.7% loss: 2.2676976,  val_loss: 2.4537988 val_acc: 77.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.31it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_acc: 76.9% loss: 1.6290557,  val_loss: 2.2458584 val_acc: 80.2%\n",
      "Validation accuracy improved from 79.92 to 80.16. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.31it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_acc: 78.0% loss: 2.3196015,  val_loss: 2.6927793 val_acc: 80.2%\n",
      "Validation accuracy improved from 80.16 to 80.21. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.31it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_acc: 78.6% loss: 1.1360536,  val_loss: 2.4149570 val_acc: 79.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.31it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_acc: 79.0% loss: 1.8820915,  val_loss: 2.2355061 val_acc: 78.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.31it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_acc: 79.4% loss: 1.7479498,  val_loss: 2.4758096 val_acc: 80.5%\n",
      "Validation accuracy improved from 80.21 to 80.52. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.31it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_acc: 79.7% loss: 1.7433438,  val_loss: 2.3659184 val_acc: 82.2%\n",
      "Validation accuracy improved from 80.52 to 82.22. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_acc: 80.0% loss: 2.4208744,  val_loss: 2.2214704 val_acc: 82.3%\n",
      "Validation accuracy improved from 82.22 to 82.30. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_acc: 80.6% loss: 1.9545448,  val_loss: 2.3992510 val_acc: 80.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_acc: 80.7% loss: 2.2471209,  val_loss: 2.4336004 val_acc: 82.7%\n",
      "Validation accuracy improved from 82.30 to 82.69. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_acc: 80.6% loss: 1.4469373,  val_loss: 2.3925102 val_acc: 82.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_acc: 80.4% loss: 2.0962808,  val_loss: 2.2889915 val_acc: 81.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_acc: 80.6% loss: 2.0345755,  val_loss: 2.1958113 val_acc: 79.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_acc: 81.1% loss: 1.7047620,  val_loss: 2.5554290 val_acc: 80.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_acc: 80.8% loss: 2.2456641,  val_loss: 2.6307769 val_acc: 80.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_acc: 81.0% loss: 1.7343358,  val_loss: 2.3919582 val_acc: 82.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_acc: 81.5% loss: 1.6256517,  val_loss: 2.5265813 val_acc: 82.8%\n",
      "Validation accuracy improved from 82.69 to 82.77. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_acc: 81.4% loss: 2.2203946,  val_loss: 2.4783771 val_acc: 81.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_acc: 81.5% loss: 1.9437058,  val_loss: 2.6995120 val_acc: 81.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_acc: 80.9% loss: 2.1849120,  val_loss: 2.3260498 val_acc: 82.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_acc: 81.6% loss: 1.4995102,  val_loss: 2.3656411 val_acc: 80.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_acc: 81.2% loss: 1.9657029,  val_loss: 2.1760323 val_acc: 79.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.32it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_acc: 81.8% loss: 1.8245485,  val_loss: 2.2829237 val_acc: 80.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_acc: 81.4% loss: 1.5184560,  val_loss: 2.2178342 val_acc: 82.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_acc: 81.5% loss: 1.3134754,  val_loss: 2.2671680 val_acc: 80.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_acc: 81.8% loss: 1.6722682,  val_loss: 2.2513735 val_acc: 81.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_acc: 80.9% loss: 2.1942825,  val_loss: 2.1725209 val_acc: 82.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_acc: 80.8% loss: 2.0407634,  val_loss: 2.5292349 val_acc: 81.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.34it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train_acc: 80.9% loss: 1.5348508,  val_loss: 2.5480428 val_acc: 80.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.34it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train_acc: 81.4% loss: 1.5764402,  val_loss: 2.2385304 val_acc: 81.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train_acc: 81.1% loss: 2.4988000,  val_loss: 2.4120250 val_acc: 81.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train_acc: 81.6% loss: 1.5668643,  val_loss: 2.1337371 val_acc: 82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.34it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: train_acc: 81.5% loss: 2.3438537,  val_loss: 2.0160556 val_acc: 81.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.34it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: train_acc: 81.2% loss: 2.2180567,  val_loss: 2.4307833 val_acc: 81.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|████████████████████| 545/545 [01:42<00:00,  5.33it/s]\n",
      "Validating..\t: 100%|██████████████████| 120/120 [00:06<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: train_acc: 81.4% loss: 1.6638585,  val_loss: 2.5816531 val_acc: 82.1%\n"
     ]
    }
   ],
   "source": [
    "results = {\"loss\":[], \"val_loss\":[], \"train_accuracy\":[], \"valid_accuracy\":[]}\n",
    "best_valacc = 0\n",
    "# Model training\n",
    "for epoch in range(num_epochs):\n",
    "    # Going through the training set\n",
    "    correct_train = 0\n",
    "    model.train()\n",
    "    for x_batch,y_batch,imgname,platename,filename,plate_idx,location,date,year,xtra,width,height in tqdm(train_dataloader, desc='Training..\\t'):        \n",
    "        y_batch = torch.as_tensor(y_batch)\n",
    "        x_batch,y_batch = x_batch.float().cuda(), y_batch.cuda()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        pred = model(x_batch)\n",
    "\n",
    "        y_batch = y_batch.type(torch.LongTensor).cuda()\n",
    "        correct_train += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_accuracy = correct_train / len(train_dataset) * 100.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    # Going through the validation set\n",
    "    correct_valid = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch,y_batch,imgname,platename,filename,plate_idx,location,date,year,xtra,width,height in tqdm(valid_dataloader, desc='Validating..\\t'):\n",
    "            y_batch = torch.as_tensor(y_batch)\n",
    "            x_batch,y_batch = x_batch.float().cuda(), y_batch.cuda()\n",
    "            pred = model(x_batch)\n",
    "\n",
    "            y_batch = y_batch.type(torch.LongTensor).cuda()\n",
    "            correct_valid += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "            val_loss = criterion(pred, y_batch)\n",
    "    valid_accuracy = correct_valid / len(valid_dataset) * 100.\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    # Printing results\n",
    "    print(f\"Epoch {epoch}: train_acc: {train_accuracy:.1f}% loss: {loss:.7f},  val_loss: {val_loss:.7f} val_acc: {valid_accuracy:.1f}%\")\n",
    "        \n",
    "    is_best = valid_accuracy > best_valacc\n",
    "    if is_best:\n",
    "        print(f\"Validation accuracy improved from {best_valacc:.2f} to {valid_accuracy:.2f}. Saving model..\")\n",
    "    best_valacc = max(valid_accuracy, best_valacc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_valacc': best_valacc,\n",
    "        'loss': results['loss'].append(loss.detach().cpu()),\n",
    "        'val_loss': results['val_loss'].append(val_loss.detach().cpu()),\n",
    "        'train_accuracy': results['train_accuracy'].append(train_accuracy),\n",
    "        'valid_accuracy': results['valid_accuracy'].append(valid_accuracy),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best, f\"{modelname}_{setting}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135fa64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5185a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f936e2-299a-41aa-bd59-8f382a57bb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('bugai': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd02d839c87abe923a8f6c83e3c07da6b84166f74541505ea2206c85c393cfdbb04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
