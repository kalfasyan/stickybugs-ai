{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available workers: 16\n"
     ]
    }
   ],
   "source": [
    "from datasets import InsectImgDataset\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "setting = 'fuji'\n",
    "if setting == 'photobox':\n",
    "    ext = '.png'\n",
    "elif setting == 'fuji':\n",
    "    ext = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting info from filenames..: 100%|██████████| 67841/67841 [00:09<00:00, 7057.34it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = InsectImgDataset(ext=ext, setting=setting, directory=DATA_DIR)\n",
    "dfs.extract_df_info()\n",
    "df = dfs.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train,val,test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = pd.read_parquet(f\"{SAVE_DIR}/df_preparation_{setting}.parquet\")\n",
    "df = pd.merge(df,df_pre, on=['filename','label','platename','imgname','date','year','plate_idx','location','xtra'])\n",
    "df = df[df.knn_outlier==0]\n",
    "df = df[df.nb_contours>0]\n",
    "df = df[~df['label'].isin(['st','vuil'])]\n",
    "df.label = df.label.apply(lambda x: 'v' if x=='v(cy)' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_plates = train_test_split(df.platename.unique(), random_state=2022, test_size=0.2, shuffle=True)[1].tolist()\n",
    "testseries = pd.Series(test_plates)\n",
    "inds = testseries.apply(lambda x: 'wortel' in x)\n",
    "inds = testseries[inds].sample(10).index.values\n",
    "wortel_plates = testseries[inds].tolist()\n",
    "test_plates = testseries[testseries.apply(lambda x: x.split('_')[1] != 'wortel')].tolist() + wortel_plates\n",
    "\n",
    "df_trainval = df[~df.platename.isin(test_plates)]\n",
    "df_test = df[df.platename.isin(test_plates)]\n",
    "\n",
    "topclasses = df['label'].value_counts().head(10).index.tolist()\n",
    "\n",
    "df = df[df['label'].isin(topclasses)]\n",
    "df_trainval = df_trainval[df_trainval['label'].isin(topclasses)]\n",
    "df_test = df_test[df_test['label'].isin(topclasses)]\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  classes=np.unique(df['label'].tolist()), \n",
    "                                                  y=df['label'].tolist())\n",
    "\n",
    "class_weights = {np.unique(df['label'])[i]:class_weights[i] for i in range(len(class_weights))}\n",
    "df['weights'] = df['label'].map(class_weights)\n",
    "\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=0.18, random_state=42, shuffle=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train.label)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,3,1);df_train.label.value_counts().plot(kind='barh');plt.title(f'train, {df_train.shape[0]}')\n",
    "plt.subplot(1,3,2);df_val.label.value_counts().plot(kind='barh');plt.title(f'val, {df_val.shape[0]}')\n",
    "plt.subplot(1,3,3);df_test.label.value_counts().plot(kind='barh');plt.title(f'test, {df_test.shape[0]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(df_train.filename.tolist()).intersection(df_test.filename.tolist())) == 0\n",
    "assert len(set(df_train.filename.tolist()).intersection(df_val.filename.tolist())) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating Pytorch Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_list_train = [\n",
    "#     A.SmallestMaxSize(max_size=150),\n",
    "#     A.Resize(height=150,width=150,p=1),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225], p=1, always_apply=True),\n",
    "    A.ShiftScaleRotate(shift_limit=0.01,rotate_limit=45, scale_limit=0, p=.5),\n",
    "    A.Rotate(limit=90, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    # A.RandomGamma(p=0.5),\n",
    "     A.RandomBrightnessContrast(p=0.2),\n",
    "     A.GaussianBlur(blur_limit=(3,3), p=0.1)\n",
    "]\n",
    "\n",
    "transforms_list_test = [\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                p=1, \n",
    "                always_apply=True)\n",
    "]\n",
    "\n",
    "train_dataset = InsectImgDataset(df=df_train.reset_index(drop=True), transform=A.Compose(transforms_list_train))\n",
    "valid_dataset = InsectImgDataset(df=df_val.reset_index(drop=True), transform=A.Compose(transforms_list_test))\n",
    "test_dataset = InsectImgDataset(df=df_test.reset_index(drop=True), transform=A.Compose(transforms_list_test))\n",
    "\n",
    "batch_size = 32\n",
    "batch_size_val = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size_val, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size_val, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "\n",
    "# plt.imshow(train_dataset[0][0]); plt.title(f\"Example train image, class:{train_dataset[0][1]}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: True\n"
     ]
    }
   ],
   "source": [
    "modelname = \"densenet121\"\n",
    "model = model_selector(modelname, pretrained=True)\n",
    "try:\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(num_ftrs,len(topclasses))\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs,len(topclasses))\n",
    "except:\n",
    "    pass\n",
    "# Choosing whether to train on a gpu\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')# Number of gpus\n",
    "model = model.to('cuda', dtype=torch.float)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "class_sample_count = np.unique(df_train.label, return_counts=True)[1]\n",
    "weight = 1. / class_sample_count  \n",
    "criterion = nn.CrossEntropyLoss(weight=torch.Tensor(weight).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=.001)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, cycle_momentum=False, mode=\"triangular2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, eps=1e-3, amsgrad=True)\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, cycle_momentum=False, mode=\"triangular2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:48<00:00,  8.14it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 25.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_acc: 66.6% loss: 0.4318833,  val_loss: 0.7225544 val_acc: 75.3%\n",
      "Validation accuracy improved from 0.00 to 75.25. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:46<00:00,  8.28it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_acc: 74.9% loss: 1.0076646,  val_loss: 1.0404285 val_acc: 79.2%\n",
      "Validation accuracy improved from 75.25 to 79.24. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:46<00:00,  8.30it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_acc: 77.1% loss: 0.4449868,  val_loss: 0.9189702 val_acc: 81.6%\n",
      "Validation accuracy improved from 79.24 to 81.60. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.24it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_acc: 78.3% loss: 0.6003480,  val_loss: 1.1241573 val_acc: 79.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.21it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_acc: 79.0% loss: 0.4494151,  val_loss: 0.7853395 val_acc: 79.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.23it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_acc: 79.5% loss: 0.5288391,  val_loss: 1.1815410 val_acc: 81.7%\n",
      "Validation accuracy improved from 81.60 to 81.66. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.22it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_acc: 80.0% loss: 0.4556445,  val_loss: 0.9729115 val_acc: 81.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:48<00:00,  8.20it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_acc: 80.4% loss: 0.3308048,  val_loss: 0.8535368 val_acc: 82.8%\n",
      "Validation accuracy improved from 81.66 to 82.84. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:48<00:00,  8.20it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_acc: 80.8% loss: 0.1702431,  val_loss: 0.9262734 val_acc: 82.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.22it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_acc: 81.3% loss: 0.4019126,  val_loss: 1.2380747 val_acc: 83.4%\n",
      "Validation accuracy improved from 82.84 to 83.45. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.24it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_acc: 81.5% loss: 0.2252885,  val_loss: 1.0815934 val_acc: 83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.22it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_acc: 81.9% loss: 0.6100410,  val_loss: 0.9738610 val_acc: 83.5%\n",
      "Validation accuracy improved from 83.45 to 83.50. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.22it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_acc: 81.8% loss: 0.2551393,  val_loss: 0.9658522 val_acc: 80.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.23it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_acc: 82.3% loss: 0.2738634,  val_loss: 0.9103787 val_acc: 82.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.22it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_acc: 82.6% loss: 0.5761556,  val_loss: 1.0275760 val_acc: 82.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.23it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_acc: 82.6% loss: 0.5223772,  val_loss: 1.0444511 val_acc: 82.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.26it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_acc: 82.9% loss: 0.4945675,  val_loss: 0.9846647 val_acc: 83.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.25it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_acc: 83.3% loss: 0.6813726,  val_loss: 0.9633948 val_acc: 83.6%\n",
      "Validation accuracy improved from 83.50 to 83.56. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.25it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_acc: 82.9% loss: 0.3477430,  val_loss: 1.0345953 val_acc: 83.8%\n",
      "Validation accuracy improved from 83.56 to 83.77. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.25it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_acc: 83.7% loss: 0.2822069,  val_loss: 0.9928275 val_acc: 82.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.26it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_acc: 83.6% loss: 0.1855593,  val_loss: 0.9319707 val_acc: 81.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.26it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:06<00:00, 27.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_acc: 83.6% loss: 0.4489720,  val_loss: 0.9703467 val_acc: 82.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:46<00:00,  8.28it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_acc: 83.5% loss: 0.3226572,  val_loss: 1.0993682 val_acc: 83.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.28it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_acc: 84.2% loss: 0.7868232,  val_loss: 1.1907160 val_acc: 82.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.26it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_acc: 84.3% loss: 0.2377622,  val_loss: 1.0878478 val_acc: 83.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.26it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_acc: 84.5% loss: 0.3518203,  val_loss: 0.8653550 val_acc: 83.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.28it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_acc: 84.4% loss: 0.4754623,  val_loss: 1.3535534 val_acc: 84.2%\n",
      "Validation accuracy improved from 83.77 to 84.17. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.28it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_acc: 84.9% loss: 0.3140724,  val_loss: 1.1654922 val_acc: 83.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.26it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_acc: 85.2% loss: 0.4289881,  val_loss: 1.2401690 val_acc: 83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.26it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_acc: 85.4% loss: 0.3038255,  val_loss: 1.1198983 val_acc: 83.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.27it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_acc: 85.2% loss: 0.1591282,  val_loss: 1.1751963 val_acc: 83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:47<00:00,  8.27it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_acc: 85.1% loss: 0.3552686,  val_loss: 1.3341429 val_acc: 84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:46<00:00,  8.28it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_acc: 85.6% loss: 0.3493392,  val_loss: 1.5954860 val_acc: 82.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:48<00:00,  8.13it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train_acc: 85.2% loss: 0.3731120,  val_loss: 1.9714326 val_acc: 82.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:49<00:00,  8.11it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train_acc: 85.8% loss: 0.2389080,  val_loss: 2.0130739 val_acc: 82.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:50<00:00,  8.04it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train_acc: 85.8% loss: 0.3929743,  val_loss: 0.9789816 val_acc: 83.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:49<00:00,  8.06it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 27.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train_acc: 85.9% loss: 1.0786091,  val_loss: 1.6956897 val_acc: 83.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:49<00:00,  8.07it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 26.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: train_acc: 85.9% loss: 0.8232835,  val_loss: 1.2603359 val_acc: 82.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:49<00:00,  8.12it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 26.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: train_acc: 86.0% loss: 0.3849578,  val_loss: 0.9494644 val_acc: 83.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:50<00:00,  7.99it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: train_acc: 87.1% loss: 0.3359847,  val_loss: 0.9839286 val_acc: 82.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 886/886 [01:49<00:00,  8.06it/s]\n",
      "Validating..\t: 100%|██████████| 195/195 [00:07<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: train_acc: 86.5% loss: 0.6617618,  val_loss: 1.9878068 val_acc: 82.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t:   4%|▍         | 38/886 [00:05<01:53,  7.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-353361e44d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_train\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/objdetect/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/objdetect/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/objdetect/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/objdetect/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/objdetect/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {\"loss\":[], \"val_loss\":[], \"train_accuracy\":[], \"valid_accuracy\":[]}\n",
    "best_valacc = 0\n",
    "# Model training\n",
    "for epoch in range(num_epochs):\n",
    "    # Going through the training set\n",
    "    correct_train = 0\n",
    "    model.train()\n",
    "    for x_batch,y_batch,imgname,platename,filename,plate_idx,location,date,year,xtra,width,height in tqdm(train_dataloader, desc='Training..\\t'):        \n",
    "        y_batch = torch.as_tensor(le.transform(y_batch))#.type(torch.LongTensor)\n",
    "        x_batch,y_batch = x_batch.float().cuda(), y_batch.cuda()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        pred = model(x_batch)\n",
    "\n",
    "        y_batch = y_batch.type(torch.LongTensor).cuda()\n",
    "        correct_train += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_accuracy = correct_train / len(train_dataset) * 100.\n",
    "    \n",
    "    # Going through the validation set\n",
    "    correct_valid = 0\n",
    "    model.eval()\n",
    "    for x_batch,y_batch,imgname,platename,filename,plate_idx,location,date,year,xtra,width,height in tqdm(valid_dataloader, desc='Validating..\\t'):\n",
    "        y_batch = torch.as_tensor(le.transform(y_batch))#.type(torch.LongTensor)\n",
    "        x_batch,y_batch = x_batch.float().cuda(), y_batch.cuda()\n",
    "        pred = model(x_batch)\n",
    "\n",
    "        y_batch = y_batch.type(torch.LongTensor).cuda()\n",
    "        correct_valid += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "        val_loss = criterion(pred, y_batch)\n",
    "    valid_accuracy = correct_valid / len(valid_dataset) * 100.\n",
    "\n",
    "    scheduler.step()\n",
    "#     early_stopping(val_loss, model)\n",
    "#     if early_stopping.early_stop:\n",
    "#         print(\"Early stopping\")\n",
    "#         break\n",
    "\n",
    "        # Printing results\n",
    "    print(f\"Epoch {epoch}: train_acc: {train_accuracy:.1f}% loss: {loss:.7f},  val_loss: {val_loss:.7f} val_acc: {valid_accuracy:.1f}%\")\n",
    "        \n",
    "    is_best = valid_accuracy > best_valacc\n",
    "    if is_best:\n",
    "        print(f\"Validation accuracy improved from {best_valacc:.2f} to {valid_accuracy:.2f}. Saving model..\")\n",
    "    best_valacc = max(valid_accuracy, best_valacc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_valacc': best_valacc,\n",
    "        'loss': results['loss'].append(loss.detach().cpu()),\n",
    "        'val_loss': results['val_loss'].append(val_loss.detach().cpu()),\n",
    "        'train_accuracy': results['train_accuracy'].append(train_accuracy),\n",
    "        'valid_accuracy': results['valid_accuracy'].append(valid_accuracy),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best, f\"{modelname}_{setting}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('objdetect': conda)",
   "language": "python",
   "name": "python37864bitobjdetectconda8045af5fdfef4ca9b47f908473881f2a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
