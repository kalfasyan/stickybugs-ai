{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecdc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c3800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available workers: 16\n"
     ]
    }
   ],
   "source": [
    "from datasets import InsectImgDataset\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "setting = 'photobox'\n",
    "if setting == 'photobox':\n",
    "    ext = '.png'\n",
    "elif setting == 'fuji':\n",
    "    ext = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5bdbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting info from filenames..: 100%|████████████████████████████████████████████████████████████████| 28363/28363 [00:03<00:00, 7810.50it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = InsectImgDataset(ext=ext, setting=setting, directory=DATA_DIR)\n",
    "dfs.extract_df_info()\n",
    "df = dfs.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71459b84",
   "metadata": {},
   "source": [
    "# Creating train,val,test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854cb3e",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9db1aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>imgname</th>\n",
       "      <th>platename</th>\n",
       "      <th>year</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>xtra</th>\n",
       "      <th>plate_idx</th>\n",
       "      <th>blur</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_cnt_area</th>\n",
       "      <th>mean_cnt_perimeter</th>\n",
       "      <th>std_cnt_area</th>\n",
       "      <th>std_cnt_perimeter</th>\n",
       "      <th>R</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>knn_outlier</th>\n",
       "      <th>knn_outlier_score</th>\n",
       "      <th>txt_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_UNDISTORTED_herent_w28_1-90_4056x3040_202...</td>\n",
       "      <td>UNDISTORTED_herent_w28_1-90_4056x3040_20200703...</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w28</td>\n",
       "      <td>1-90</td>\n",
       "      <td>11869</td>\n",
       "      <td>42.842744</td>\n",
       "      <td>...</td>\n",
       "      <td>116.875000</td>\n",
       "      <td>40.238329</td>\n",
       "      <td>132.378423</td>\n",
       "      <td>37.283882</td>\n",
       "      <td>205.431857</td>\n",
       "      <td>204.239418</td>\n",
       "      <td>210.109485</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132859</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_herent_w27_1-30_4056x3040_23062020145640....</td>\n",
       "      <td>herent_w27_1-30_4056x3040_23062020145640.jpg</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w27</td>\n",
       "      <td>1-30</td>\n",
       "      <td>25928</td>\n",
       "      <td>25.307896</td>\n",
       "      <td>...</td>\n",
       "      <td>60.870968</td>\n",
       "      <td>16.198733</td>\n",
       "      <td>835.417788</td>\n",
       "      <td>101.347855</td>\n",
       "      <td>133.678222</td>\n",
       "      <td>142.086978</td>\n",
       "      <td>129.338667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552473</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_herent_w27_1-30_4056x3040_23062020145640....</td>\n",
       "      <td>herent_w27_1-30_4056x3040_23062020145640.jpg</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w27</td>\n",
       "      <td>1-30</td>\n",
       "      <td>25932</td>\n",
       "      <td>21.129386</td>\n",
       "      <td>...</td>\n",
       "      <td>54.502994</td>\n",
       "      <td>16.757472</td>\n",
       "      <td>555.751472</td>\n",
       "      <td>80.321145</td>\n",
       "      <td>136.486622</td>\n",
       "      <td>148.774933</td>\n",
       "      <td>143.012622</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349623</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_herent_w27_1-30_4056x3040_23062020145640....</td>\n",
       "      <td>herent_w27_1-30_4056x3040_23062020145640.jpg</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w27</td>\n",
       "      <td>1-30</td>\n",
       "      <td>25969</td>\n",
       "      <td>25.211150</td>\n",
       "      <td>...</td>\n",
       "      <td>31.208333</td>\n",
       "      <td>16.667472</td>\n",
       "      <td>155.566533</td>\n",
       "      <td>49.494496</td>\n",
       "      <td>146.883956</td>\n",
       "      <td>154.641333</td>\n",
       "      <td>143.112933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153815</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/EE7455C074558BE9/backups/data_backups/ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020_herent_w27_1-30_4056x3040_23062020145640....</td>\n",
       "      <td>herent_w27_1-30_4056x3040_23062020145640.jpg</td>\n",
       "      <td>2020</td>\n",
       "      <td>herent</td>\n",
       "      <td>w27</td>\n",
       "      <td>1-30</td>\n",
       "      <td>25971</td>\n",
       "      <td>34.813996</td>\n",
       "      <td>...</td>\n",
       "      <td>46.980226</td>\n",
       "      <td>14.289273</td>\n",
       "      <td>555.609924</td>\n",
       "      <td>87.069623</td>\n",
       "      <td>137.986843</td>\n",
       "      <td>144.721766</td>\n",
       "      <td>132.789095</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398847</td>\n",
       "      <td>bl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  label  \\\n",
       "0  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "1  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "2  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "3  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "4  /mnt/EE7455C074558BE9/backups/data_backups/ima...      0   \n",
       "\n",
       "                                             imgname  \\\n",
       "0  2020_UNDISTORTED_herent_w28_1-90_4056x3040_202...   \n",
       "1  2020_herent_w27_1-30_4056x3040_23062020145640....   \n",
       "2  2020_herent_w27_1-30_4056x3040_23062020145640....   \n",
       "3  2020_herent_w27_1-30_4056x3040_23062020145640....   \n",
       "4  2020_herent_w27_1-30_4056x3040_23062020145640....   \n",
       "\n",
       "                                           platename  year location date  \\\n",
       "0  UNDISTORTED_herent_w28_1-90_4056x3040_20200703...  2020   herent  w28   \n",
       "1       herent_w27_1-30_4056x3040_23062020145640.jpg  2020   herent  w27   \n",
       "2       herent_w27_1-30_4056x3040_23062020145640.jpg  2020   herent  w27   \n",
       "3       herent_w27_1-30_4056x3040_23062020145640.jpg  2020   herent  w27   \n",
       "4       herent_w27_1-30_4056x3040_23062020145640.jpg  2020   herent  w27   \n",
       "\n",
       "   xtra plate_idx       blur  ...  mean_cnt_area  mean_cnt_perimeter  \\\n",
       "0  1-90     11869  42.842744  ...     116.875000           40.238329   \n",
       "1  1-30     25928  25.307896  ...      60.870968           16.198733   \n",
       "2  1-30     25932  21.129386  ...      54.502994           16.757472   \n",
       "3  1-30     25969  25.211150  ...      31.208333           16.667472   \n",
       "4  1-30     25971  34.813996  ...      46.980226           14.289273   \n",
       "\n",
       "   std_cnt_area  std_cnt_perimeter           R           G           B  \\\n",
       "0    132.378423          37.283882  205.431857  204.239418  210.109485   \n",
       "1    835.417788         101.347855  133.678222  142.086978  129.338667   \n",
       "2    555.751472          80.321145  136.486622  148.774933  143.012622   \n",
       "3    155.566533          49.494496  146.883956  154.641333  143.112933   \n",
       "4    555.609924          87.069623  137.986843  144.721766  132.789095   \n",
       "\n",
       "   knn_outlier  knn_outlier_score  txt_label  \n",
       "0            0           0.132859         bl  \n",
       "1            0           0.552473         bl  \n",
       "2            0           0.349623         bl  \n",
       "3            0           0.153815         bl  \n",
       "4            0           0.398847         bl  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre = pd.read_parquet(f\"{SAVE_DIR}/df_preparation_{setting}.parquet\")\n",
    "df = pd.merge(df,df_pre, on=['filename','label','platename','imgname','date','year','plate_idx','location','xtra'])\n",
    "df = df[df.knn_outlier==0]\n",
    "df = df[df.nb_contours>0]\n",
    "\n",
    "oe = OrdinalEncoder(cols=['label'],mapping=[{'col':'label', 'mapping':{'bl':0,'wswl':1,'sp':2,'t':3,'sw':4,'k':5,'m':6,'c':7,'v':8,'wmv':9,'wrl':10}}])\n",
    "df['txt_label'] = df['label']\n",
    "df['label'] = oe.fit_transform(df.label)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f746cd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_plates = train_test_split(df.platename.unique(), random_state=2022, test_size=0.2, shuffle=True)[1].tolist()\n",
    "testseries = pd.Series(test_plates)\n",
    "inds = testseries.apply(lambda x: 'wortel' in x)\n",
    "inds = testseries[inds].sample(11).index.values\n",
    "wortel_plates = testseries[inds].tolist()\n",
    "test_plates = testseries[testseries.apply(lambda x: x.split('_')[1] != 'wortel')].tolist() + wortel_plates\n",
    "\n",
    "df_trainval = df[~df.platename.isin(test_plates)]\n",
    "df_test = df[df.platename.isin(test_plates)]\n",
    "\n",
    "topclasses = df['label'].value_counts().head(11).index.tolist()\n",
    "\n",
    "df = df[df['label'].isin(topclasses)]\n",
    "df_trainval = df_trainval[df_trainval['label'].isin(topclasses)]\n",
    "df_test = df_test[df_test['label'].isin(topclasses)]\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  classes=np.unique(df['label'].tolist()), \n",
    "                                                  y=df['label'].tolist())\n",
    "\n",
    "class_weights = {np.unique(df['label'])[i]:class_weights[i] for i in range(len(class_weights))}\n",
    "df['weights'] = df['label'].map(class_weights)\n",
    "\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=0.18, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,3,1);df_train.txt_label.value_counts().plot(kind='barh');plt.title(f'train, {df_train.shape[0]}')\n",
    "plt.subplot(1,3,2);df_val.txt_label.value_counts().plot(kind='barh');plt.title(f'val, {df_val.shape[0]}')\n",
    "plt.subplot(1,3,3);df_test.txt_label.value_counts().plot(kind='barh');plt.title(f'test, {df_test.shape[0]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fdd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(df_train.filename.tolist()).intersection(df_test.filename.tolist())) == 0\n",
    "assert len(set(df_train.filename.tolist()).intersection(df_val.filename.tolist())) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af1bb016-ae27-456f-9cf1-294532cc7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(f\"{SAVE_DIR}/df_train_{setting}.parquet\")\n",
    "df_val.to_parquet(f\"{SAVE_DIR}/df_val_{setting}.parquet\")\n",
    "df_test.to_parquet(f\"{SAVE_DIR}/df_test_{setting}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c7b1e5-a740-4530-ae5f-24299737f2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     3284\n",
       "8     3175\n",
       "7     2798\n",
       "4     1526\n",
       "3     1483\n",
       "0     1402\n",
       "6      962\n",
       "5      665\n",
       "10     597\n",
       "2      505\n",
       "1      449\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3166c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating Pytorch Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61c23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_list_train = [\n",
    "#     A.SmallestMaxSize(max_size=150),\n",
    "#     A.Resize(height=150,width=150,p=1),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225], p=1, always_apply=True),\n",
    "    A.ShiftScaleRotate(shift_limit=0.01,rotate_limit=45, scale_limit=0, p=.5),\n",
    "    A.Rotate(limit=90, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    # A.RandomGamma(p=0.5),\n",
    "     A.RandomBrightnessContrast(p=0.2),\n",
    "     A.GaussianBlur(blur_limit=(3,3), p=0.1)\n",
    "]\n",
    "\n",
    "transforms_list_test = [\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                p=1, \n",
    "                always_apply=True)\n",
    "]\n",
    "\n",
    "train_dataset = InsectImgDataset(df=df_train.reset_index(drop=True), transform=A.Compose(transforms_list_train))\n",
    "valid_dataset = InsectImgDataset(df=df_val.reset_index(drop=True), transform=A.Compose(transforms_list_test))\n",
    "test_dataset = InsectImgDataset(df=df_test.reset_index(drop=True), transform=A.Compose(transforms_list_test))\n",
    "\n",
    "batch_size = 32\n",
    "batch_size_val = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size_val, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size_val, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "\n",
    "# plt.imshow(train_dataset[0][0]); plt.title(f\"Example train image, class:{train_dataset[0][1]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f75ae",
   "metadata": {},
   "source": [
    "# Defining the model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234389bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5993df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: True\n"
     ]
    }
   ],
   "source": [
    "modelname = \"vgg19\"\n",
    "model = model_selector(modelname, pretrained=True)\n",
    "\n",
    "if modelname.startswith(\"dense\"):\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(num_ftrs,len(topclasses))\n",
    "if modelname.startswith(\"resn\"):\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs,len(topclasses))\n",
    "if modelname.startswith(\"efficient\"):\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_ftrs,len(topclasses))\n",
    "if modelname.startswith(\"vgg\"):\n",
    "    num_ftrs = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(num_ftrs, len(topclasses))\n",
    "    \n",
    "# Choosing whether to train on a gpu\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')# Number of gpus\n",
    "model = model.to('cuda', dtype=torch.float)\n",
    "\n",
    "num_epochs = 40\n",
    "\n",
    "class_sample_count = np.unique(df_train.label, return_counts=True)[1]\n",
    "weight = 1. / class_sample_count  \n",
    "criterion = nn.CrossEntropyLoss(weight=torch.Tensor(weight).cuda(), label_smoothing=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "276ad0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=.001)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, cycle_momentum=False, mode=\"triangular2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e6d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, eps=1e-3, amsgrad=True)\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, cycle_momentum=False, mode=\"triangular2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cc53eb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ace6f25",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:55<00:00,  4.54it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:08<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_acc: 51.3% loss: 1.9849348,  val_loss: 1.4883066 val_acc: 66.2%\n",
      "Validation accuracy improved from 0.00 to 66.18. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:52<00:00,  4.68it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_acc: 65.2% loss: 1.5419004,  val_loss: 1.6327716 val_acc: 68.0%\n",
      "Validation accuracy improved from 66.18 to 68.05. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:52<00:00,  4.70it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_acc: 69.9% loss: 1.2769473,  val_loss: 1.8022122 val_acc: 72.3%\n",
      "Validation accuracy improved from 68.05 to 72.26. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.72it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_acc: 72.8% loss: 1.5444527,  val_loss: 1.8638605 val_acc: 76.1%\n",
      "Validation accuracy improved from 72.26 to 76.07. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [07:39<00:00,  1.15it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [01:54<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_acc: 74.5% loss: 1.9911076,  val_loss: 1.3020315 val_acc: 75.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [03:23<00:00,  2.60it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:11<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_acc: 75.1% loss: 1.3541598,  val_loss: 1.2696466 val_acc: 77.4%\n",
      "Validation accuracy improved from 76.07 to 77.43. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.71it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_acc: 75.5% loss: 1.9119077,  val_loss: 1.6381106 val_acc: 76.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.71it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_acc: 76.5% loss: 2.4594264,  val_loss: 1.4457905 val_acc: 78.4%\n",
      "Validation accuracy improved from 77.43 to 78.37. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.72it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_acc: 77.4% loss: 1.1614540,  val_loss: 1.2842218 val_acc: 78.9%\n",
      "Validation accuracy improved from 78.37 to 78.89. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.73it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_acc: 77.5% loss: 1.7303791,  val_loss: 1.3705379 val_acc: 76.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.72it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_acc: 78.0% loss: 1.5033057,  val_loss: 1.3561068 val_acc: 76.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.72it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_acc: 78.5% loss: 1.2375011,  val_loss: 1.2968638 val_acc: 79.5%\n",
      "Validation accuracy improved from 78.89 to 79.48. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.73it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_acc: 78.9% loss: 1.1842856,  val_loss: 1.2687075 val_acc: 77.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.73it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_acc: 78.2% loss: 1.8088849,  val_loss: 1.3712442 val_acc: 80.0%\n",
      "Validation accuracy improved from 79.48 to 80.02. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.73it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_acc: 78.9% loss: 1.4301217,  val_loss: 1.3516273 val_acc: 77.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.73it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_acc: 77.9% loss: 0.9652441,  val_loss: 1.2754959 val_acc: 77.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.72it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_acc: 79.2% loss: 1.9430428,  val_loss: 1.3478162 val_acc: 78.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.73it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_acc: 79.4% loss: 1.3082550,  val_loss: 1.3347888 val_acc: 79.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.73it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_acc: 79.8% loss: 1.4705634,  val_loss: 1.4377042 val_acc: 78.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.73it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_acc: 79.8% loss: 1.3887761,  val_loss: 1.2865155 val_acc: 80.4%\n",
      "Validation accuracy improved from 80.02 to 80.40. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.75it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_acc: 78.7% loss: 0.9933304,  val_loss: 1.1985464 val_acc: 78.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.75it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_acc: 79.5% loss: 2.2500606,  val_loss: 1.2299111 val_acc: 79.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:51<00:00,  4.75it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_acc: 79.7% loss: 1.7547407,  val_loss: 1.4182749 val_acc: 78.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.75it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_acc: 79.0% loss: 1.3957316,  val_loss: 1.4435940 val_acc: 80.6%\n",
      "Validation accuracy improved from 80.40 to 80.62. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.75it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_acc: 79.3% loss: 1.1622320,  val_loss: 1.5298669 val_acc: 78.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.75it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_acc: 80.3% loss: 1.2242184,  val_loss: 1.5536178 val_acc: 79.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.75it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_acc: 80.1% loss: 0.9901829,  val_loss: 1.2322255 val_acc: 81.0%\n",
      "Validation accuracy improved from 80.62 to 80.97. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.76it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_acc: 79.1% loss: 1.2395096,  val_loss: 1.3123116 val_acc: 79.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.76it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_acc: 79.1% loss: 1.2421407,  val_loss: 1.5921766 val_acc: 79.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.75it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_acc: 80.2% loss: 1.1123899,  val_loss: 1.4518180 val_acc: 81.5%\n",
      "Validation accuracy improved from 80.97 to 81.54. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.78it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_acc: 80.5% loss: 1.4702556,  val_loss: 1.5240166 val_acc: 82.0%\n",
      "Validation accuracy improved from 81.54 to 81.97. Saving model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:49<00:00,  4.80it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_acc: 79.4% loss: 1.6011167,  val_loss: 1.6580616 val_acc: 76.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.78it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_acc: 79.0% loss: 1.0387098,  val_loss: 1.7032712 val_acc: 76.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.78it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train_acc: 79.7% loss: 1.2187583,  val_loss: 1.2680802 val_acc: 79.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.76it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train_acc: 80.1% loss: 1.2808022,  val_loss: 1.2814059 val_acc: 80.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:49<00:00,  4.79it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train_acc: 79.1% loss: 1.2279747,  val_loss: 1.3379124 val_acc: 80.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.78it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train_acc: 79.4% loss: 1.2342086,  val_loss: 1.4472892 val_acc: 78.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.78it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: train_acc: 79.6% loss: 1.7978057,  val_loss: 1.2669835 val_acc: 79.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.78it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: train_acc: 79.5% loss: 1.1189500,  val_loss: 1.3091031 val_acc: 78.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 527/527 [01:50<00:00,  4.76it/s]\n",
      "Validating..\t: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:07<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: train_acc: 79.1% loss: 1.9463062,  val_loss: 1.4322836 val_acc: 79.9%\n"
     ]
    }
   ],
   "source": [
    "results = {\"loss\":[], \"val_loss\":[], \"train_accuracy\":[], \"valid_accuracy\":[]}\n",
    "best_valacc = 0\n",
    "# Model training\n",
    "for epoch in range(num_epochs):\n",
    "    # Going through the training set\n",
    "    correct_train = 0\n",
    "    model.train()\n",
    "    for x_batch,y_batch,imgname,platename,filename,plate_idx,location,date,year,xtra,width,height in tqdm(train_dataloader, desc='Training..\\t'):        \n",
    "        y_batch = torch.as_tensor(y_batch)\n",
    "        x_batch,y_batch = x_batch.float().cuda(), y_batch.cuda()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        pred = model(x_batch)\n",
    "\n",
    "        y_batch = y_batch.type(torch.LongTensor).cuda()\n",
    "        correct_train += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_accuracy = correct_train / len(train_dataset) * 100.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    # Going through the validation set\n",
    "    correct_valid = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch,y_batch,imgname,platename,filename,plate_idx,location,date,year,xtra,width,height in tqdm(valid_dataloader, desc='Validating..\\t'):\n",
    "            y_batch = torch.as_tensor(y_batch)\n",
    "            x_batch,y_batch = x_batch.float().cuda(), y_batch.cuda()\n",
    "            pred = model(x_batch)\n",
    "\n",
    "            y_batch = y_batch.type(torch.LongTensor).cuda()\n",
    "            correct_valid += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "            val_loss = criterion(pred, y_batch)\n",
    "    valid_accuracy = correct_valid / len(valid_dataset) * 100.\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    # Printing results\n",
    "    print(f\"Epoch {epoch}: train_acc: {train_accuracy:.1f}% loss: {loss:.7f},  val_loss: {val_loss:.7f} val_acc: {valid_accuracy:.1f}%\")\n",
    "        \n",
    "    is_best = valid_accuracy > best_valacc\n",
    "    if is_best:\n",
    "        print(f\"Validation accuracy improved from {best_valacc:.2f} to {valid_accuracy:.2f}. Saving model..\")\n",
    "    best_valacc = max(valid_accuracy, best_valacc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_valacc': best_valacc,\n",
    "        'loss': results['loss'].append(loss.detach().cpu()),\n",
    "        'val_loss': results['val_loss'].append(val_loss.detach().cpu()),\n",
    "        'train_accuracy': results['train_accuracy'].append(train_accuracy),\n",
    "        'valid_accuracy': results['valid_accuracy'].append(valid_accuracy),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best, f\"{modelname}_{setting}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135fa64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5185a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f936e2-299a-41aa-bd59-8f382a57bb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('bugai': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd02d839c87abe923a8f6c83e3c07da6b84166f74541505ea2206c85c393cfdbb04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
