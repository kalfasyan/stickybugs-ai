{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e44e0a93-52b4-4e9d-af7e-ae71358581e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47965f8-9f26-43a0-be8b-d7170768f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython\n",
    "# IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e062f962-121f-496a-a946-212829c1e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icevision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2830457f-95d9-4075-a4ae-bda450e523d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b0cb4515874438a7c6e2b7b05ce544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1m\u001b[34m\u001b[1mAutofixing records\u001b[0m\u001b[1m\u001b[34m\u001b[0m\u001b[1m\u001b[0m | \u001b[36micevision.parsers.parser\u001b[0m:\u001b[36mparse\u001b[0m:\u001b[36m122\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823d1e992c274802952b9376c4849670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://cvbp-secondary.z19.web.core.windows.net/datasets/object_detection/odFridgeObjects.zip\"\n",
    "dest_dir = \"fridge\"\n",
    "data_dir = icedata.load_data(url, dest_dir)\n",
    "\n",
    "parser = parsers.VOCBBoxParser(annotations_dir=data_dir / \"odFridgeObjects/annotations\", images_dir=data_dir / \"odFridgeObjects/images\")\n",
    "\n",
    "train_records, valid_records = parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5201573d-58ec-4a9c-b882-e36f67d74281",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 384\n",
    "train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=(image_size, image_size), presize=512), tfms.A.Normalize()])\n",
    "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad((image_size, image_size)), tfms.A.Normalize()])\n",
    "\n",
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4282c1ee-9281-4083-bab9-8bed5c4e550d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'icevision.models.mmdet.models.vfnet' from '/home/kalfasyan/anaconda3/envs/sahi/lib/python3.9/site-packages/icevision/models/mmdet/models/vfnet/__init__.py'> <icevision.models.mmdet.models.vfnet.backbones.resnet_fpn.MMDetVFNETBackboneConfig object at 0x7fe9744b44c0> {}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c36416f9b347dd9f335757bf7296cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131902412 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 16:05:22,339 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
      "2021-12-13 16:05:22,339 - mmcv - INFO - load model from: torchvision://resnet50\n",
      "2021-12-13 16:05:22,340 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/kalfasyan/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039776f84cc540119219758ecf36b28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 16:05:33,391 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2021-12-13 16:05:33,421 - mmcv - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2021-12-13 16:05:33,446 - mmcv - INFO - initialize VFNetHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'vfnet_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
      "2021-12-13 16:05:33,476 - mmcv - INFO - \n",
      "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,477 - mmcv - INFO - \n",
      "backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,477 - mmcv - INFO - \n",
      "backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,477 - mmcv - INFO - \n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,478 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,478 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,478 - mmcv - INFO - \n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,479 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,479 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,480 - mmcv - INFO - \n",
      "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,480 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,480 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,481 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,481 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,481 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,481 - mmcv - INFO - \n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,482 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,482 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,482 - mmcv - INFO - \n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,483 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,483 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,484 - mmcv - INFO - \n",
      "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,484 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,485 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,485 - mmcv - INFO - \n",
      "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,485 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,485 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,486 - mmcv - INFO - \n",
      "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,486 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,487 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,487 - mmcv - INFO - \n",
      "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,487 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,487 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,488 - mmcv - INFO - \n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,488 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,489 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,489 - mmcv - INFO - \n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,489 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,489 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,490 - mmcv - INFO - \n",
      "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,490 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,490 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,491 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,491 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,492 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,492 - mmcv - INFO - \n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,492 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,493 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,493 - mmcv - INFO - \n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,493 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,494 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,494 - mmcv - INFO - \n",
      "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,494 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,494 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,495 - mmcv - INFO - \n",
      "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,495 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,497 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,497 - mmcv - INFO - \n",
      "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,497 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,497 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,498 - mmcv - INFO - \n",
      "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,498 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,498 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,498 - mmcv - INFO - \n",
      "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,499 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,499 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,499 - mmcv - INFO - \n",
      "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,499 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,502 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,502 - mmcv - INFO - \n",
      "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,502 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,503 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,503 - mmcv - INFO - \n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,503 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,504 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,504 - mmcv - INFO - \n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,504 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,504 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,505 - mmcv - INFO - \n",
      "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,505 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,505 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,506 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,506 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,506 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,506 - mmcv - INFO - \n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,507 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,507 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,507 - mmcv - INFO - \n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,507 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,507 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,508 - mmcv - INFO - \n",
      "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,508 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,508 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,508 - mmcv - INFO - \n",
      "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,509 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,509 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,509 - mmcv - INFO - \n",
      "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,510 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,510 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,510 - mmcv - INFO - \n",
      "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,510 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,511 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,511 - mmcv - INFO - \n",
      "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,511 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,511 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,512 - mmcv - INFO - \n",
      "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,512 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,512 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,512 - mmcv - INFO - \n",
      "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,512 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,513 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,513 - mmcv - INFO - \n",
      "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,513 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,513 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,514 - mmcv - INFO - \n",
      "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,514 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,514 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,514 - mmcv - INFO - \n",
      "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,515 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,515 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,515 - mmcv - INFO - \n",
      "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,515 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,515 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,516 - mmcv - INFO - \n",
      "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,516 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,516 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,516 - mmcv - INFO - \n",
      "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,516 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,517 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,517 - mmcv - INFO - \n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,517 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,517 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,518 - mmcv - INFO - \n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,518 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,518 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,518 - mmcv - INFO - \n",
      "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,519 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,519 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,519 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,519 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,523 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,524 - mmcv - INFO - \n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,524 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,524 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,525 - mmcv - INFO - \n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,525 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,525 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,526 - mmcv - INFO - \n",
      "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,526 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,526 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,526 - mmcv - INFO - \n",
      "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,527 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,527 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,527 - mmcv - INFO - \n",
      "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,527 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,528 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,528 - mmcv - INFO - \n",
      "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,528 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,529 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2021-12-13 16:05:33,529 - mmcv - INFO - \n",
      "neck.lateral_convs.0.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,529 - mmcv - INFO - \n",
      "neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,529 - mmcv - INFO - \n",
      "neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,530 - mmcv - INFO - \n",
      "neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,530 - mmcv - INFO - \n",
      "neck.lateral_convs.2.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,530 - mmcv - INFO - \n",
      "neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,530 - mmcv - INFO - \n",
      "neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,531 - mmcv - INFO - \n",
      "neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,531 - mmcv - INFO - \n",
      "neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,531 - mmcv - INFO - \n",
      "neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,531 - mmcv - INFO - \n",
      "neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,532 - mmcv - INFO - \n",
      "neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,532 - mmcv - INFO - \n",
      "neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,532 - mmcv - INFO - \n",
      "neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,532 - mmcv - INFO - \n",
      "neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,533 - mmcv - INFO - \n",
      "neck.fpn_convs.4.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,533 - mmcv - INFO - \n",
      "bbox_head.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,533 - mmcv - INFO - \n",
      "bbox_head.cls_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,533 - mmcv - INFO - \n",
      "bbox_head.cls_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,534 - mmcv - INFO - \n",
      "bbox_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,534 - mmcv - INFO - \n",
      "bbox_head.cls_convs.1.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,534 - mmcv - INFO - \n",
      "bbox_head.cls_convs.1.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,534 - mmcv - INFO - \n",
      "bbox_head.cls_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,537 - mmcv - INFO - \n",
      "bbox_head.cls_convs.2.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,537 - mmcv - INFO - \n",
      "bbox_head.cls_convs.2.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,538 - mmcv - INFO - \n",
      "bbox_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,538 - mmcv - INFO - \n",
      "bbox_head.reg_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,538 - mmcv - INFO - \n",
      "bbox_head.reg_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,538 - mmcv - INFO - \n",
      "bbox_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,539 - mmcv - INFO - \n",
      "bbox_head.reg_convs.1.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,539 - mmcv - INFO - \n",
      "bbox_head.reg_convs.1.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,539 - mmcv - INFO - \n",
      "bbox_head.reg_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,540 - mmcv - INFO - \n",
      "bbox_head.reg_convs.2.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,540 - mmcv - INFO - \n",
      "bbox_head.reg_convs.2.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,540 - mmcv - INFO - \n",
      "bbox_head.vfnet_reg_conv.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in ConvModule  \n",
      " \n",
      "2021-12-13 16:05:33,540 - mmcv - INFO - \n",
      "bbox_head.vfnet_reg_conv.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,541 - mmcv - INFO - \n",
      "bbox_head.vfnet_reg_conv.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,541 - mmcv - INFO - \n",
      "bbox_head.vfnet_reg.weight - torch.Size([4, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,541 - mmcv - INFO - \n",
      "bbox_head.vfnet_reg.bias - torch.Size([4]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,541 - mmcv - INFO - \n",
      "bbox_head.scales.0.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,541 - mmcv - INFO - \n",
      "bbox_head.scales.1.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,542 - mmcv - INFO - \n",
      "bbox_head.scales.2.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,542 - mmcv - INFO - \n",
      "bbox_head.scales.3.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,542 - mmcv - INFO - \n",
      "bbox_head.scales.4.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,542 - mmcv - INFO - \n",
      "bbox_head.vfnet_reg_refine_dconv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,543 - mmcv - INFO - \n",
      "bbox_head.vfnet_reg_refine.weight - torch.Size([4, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,543 - mmcv - INFO - \n",
      "bbox_head.vfnet_reg_refine.bias - torch.Size([4]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2021-12-13 16:05:33,543 - mmcv - INFO - \n",
      "bbox_head.scales_refine.0.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,543 - mmcv - INFO - \n",
      "bbox_head.scales_refine.1.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,544 - mmcv - INFO - \n",
      "bbox_head.scales_refine.2.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,544 - mmcv - INFO - \n",
      "bbox_head.scales_refine.3.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,544 - mmcv - INFO - \n",
      "bbox_head.scales_refine.4.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,544 - mmcv - INFO - \n",
      "bbox_head.vfnet_cls_dconv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of VFNet  \n",
      " \n",
      "2021-12-13 16:05:33,544 - mmcv - INFO - \n",
      "bbox_head.vfnet_cls.weight - torch.Size([4, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "2021-12-13 16:05:33,546 - mmcv - INFO - \n",
      "bbox_head.vfnet_cls.bias - torch.Size([4]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: checkpoints/vfnet/vfnet_r50_fpn_mstrain_2x_coco_20201027-7cc75bd2.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.vfnet_cls.weight: copying a param with shape torch.Size([80, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([4, 256, 3, 3]).\n",
      "size mismatch for bbox_head.vfnet_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([4]).\n"
     ]
    }
   ],
   "source": [
    "# Just change the value of selection to try another model\n",
    "\n",
    "selection = 0\n",
    "\n",
    "extra_args = {}\n",
    "\n",
    "if selection == 0:\n",
    "  model_type = models.mmdet.vfnet\n",
    "  backbone = model_type.backbones.resnet50_fpn_mstrain_2x\n",
    "  #model_type = models.mmdet.faster_rcnn\n",
    "  #backbone = model_type.backbones.resnet50_fpn_1x\n",
    "  #model_type = models.mmdet.retinanet\n",
    "  #backbone = model_type.backbones.resnet50_fpn_1x\n",
    "  #model_type = models.mmdet.ssd\n",
    "  #backbone = model_type.backbones.ssd512\n",
    "\n",
    "elif selection == 1:\n",
    "  # The Retinanet model is also implemented in the torchvision library\n",
    "  model_type = models.torchvision.faster_rcnn\n",
    "  backbone = model_type.backbones.resnet50_fpn\n",
    "\n",
    "elif selection == 2:\n",
    "  model_type = models.ross.efficientdet\n",
    "  backbone = model_type.backbones.tf_lite1\n",
    "  # The efficientdet model requires an img_size parameter\n",
    "  extra_args['img_size'] = image_size\n",
    "\n",
    "elif selection == 3:\n",
    "  model_type = models.ultralytics.yolov5\n",
    "  backbone = model_type.backbones.medium\n",
    "  # The yolov5 model requires an img_size parameter\n",
    "  extra_args['img_size'] = image_size\n",
    "\n",
    "print(model_type, backbone, extra_args)\n",
    "\n",
    "model = model_type.model(backbone=backbone(pretrained=True), num_classes=len(parser.class_map), **extra_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc506528-b71d-4337-8063-8e8101c2babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = model_type.train_dl(train_ds, batch_size=16, num_workers=8, shuffle=True)\n",
    "valid_dl = model_type.valid_dl(valid_ds, batch_size=16, num_workers=8, shuffle=False)\n",
    "\n",
    "metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]\n",
    "\n",
    "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5b419d9-7e2f-4365-b33a-160482aa34c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_ModelWrap(\n",
       "  (model): VFNet(\n",
       "    (backbone): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): ResLayer(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): ResLayer(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): ResLayer(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): ResLayer(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
       "    (neck): FPN(\n",
       "      (lateral_convs): ModuleList(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (fpn_convs): ModuleList(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (3): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "        (4): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
       "    (bbox_head): VFNetHead(\n",
       "      (loss_cls): VarifocalLoss()\n",
       "      (loss_bbox): GIoULoss()\n",
       "      (cls_convs): ModuleList(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (reg_convs): ModuleList(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (vfnet_reg_conv): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (vfnet_reg): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (scales): ModuleList(\n",
       "        (0): Scale()\n",
       "        (1): Scale()\n",
       "        (2): Scale()\n",
       "        (3): Scale()\n",
       "        (4): Scale()\n",
       "      )\n",
       "      (vfnet_reg_refine_dconv): DeformConv2d(in_channels=256,\n",
       "      out_channels=256,\n",
       "      kernel_size=(3, 3),\n",
       "      stride=(1, 1),\n",
       "      padding=(1, 1),\n",
       "      dilation=(1, 1),\n",
       "      groups=1,\n",
       "      deform_groups=1,\n",
       "      bias=False)\n",
       "      (vfnet_reg_refine): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (scales_refine): ModuleList(\n",
       "        (0): Scale()\n",
       "        (1): Scale()\n",
       "        (2): Scale()\n",
       "        (3): Scale()\n",
       "        (4): Scale()\n",
       "      )\n",
       "      (vfnet_cls_dconv): DeformConv2d(in_channels=256,\n",
       "      out_channels=256,\n",
       "      kernel_size=(3, 3),\n",
       "      stride=(1, 1),\n",
       "      padding=(1, 1),\n",
       "      dilation=(1, 1),\n",
       "      groups=1,\n",
       "      deform_groups=1,\n",
       "      bias=False)\n",
       "      (vfnet_cls): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (loss_bbox_refine): GIoULoss()\n",
       "    )\n",
       "    init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'vfnet_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e3e508f-024f-40f5-a96a-e17265598cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalfasyan/anaconda3/envs/sahi/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.0004786300996784121)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAs/klEQVR4nO3deXxU9b3/8dcnO1lIIBtLEsK+r0YFqYKCS93rRtVbtbWuty5Ve6v3tlZt+2uttfZqvQrWulStIlqLWKtoQVwQCcgi+w5hS9hC9vX7+2MGjTFkI5OTybyfj8c8mDnznTPvr2PmM+d8zzlfc84hIiKhK8zrACIi4i0VAhGREKdCICIS4lQIRERCnAqBiEiIUyEQEQlxEV4HaKmUlBSXnZ3tdQwRkaCyZMmSfc651IaeC7pCkJ2dTW5urtcxRESCipltO9pz2jUkIhLiVAhEREKcCoGISIgLujECEZGjqaqqIi8vj/Lycq+jeCYmJoaMjAwiIyOb/RoVAhHpNPLy8khISCA7Oxsz8zpOu3POsX//fvLy8ujbt2+zX6ddQyLSaZSXl5OcnBySRQDAzEhOTm7xFlHAC4GZhZvZ52Y2p4Hnos3sFTPbaGaLzCw7UDl2HCjlnyt3B2r1ItJBhGoROKI1/W+PLYLbgDVHee5a4KBzbgDwCPBgoEK8tXI3N7+4lMKyqkC9hYhIi8THxwOwdetWRowY4VmOgBYCM8sAzgH+fJQmFwDP+e/PAqZYgMr5wDTff/CN+cWBWL2IBKMVM+GREXBfku/fFTO9TuSJQG8R/BH4L6D2KM/3BnYAOOeqgUIgORBBBqYlALBhb1EgVi8iwWbFTHjzVijcATjfv2/eekzF4O677+bxxx//8vF9993Hr371K6ZMmcK4ceMYOXIk//jHPxpdR01NDT/5yU84/vjjGTVqFNOnTwfgqquu4o033viy3ZVXXtnkuporYIXAzM4F8p1zS9pgXdebWa6Z5RYUFLRqHb27dSEmMowN2iIQEYD3H4Cqsq8vqyrzLW+ladOmMXPmV4Vk5syZXH311fz9739n6dKlzJs3jzvvvJPGpgh++umnSUxMZPHixSxevJinnnqKLVu2cO211/Lss88CUFhYyCeffMI555zT6qx1BfLw0YnA+WZ2NhADdDWzF5xz/1GnzU4gE8gzswggEdhff0XOuRnADICcnJxWTbIcHmb0T41XIRARn8K8li1vhrFjx5Kfn8+uXbsoKCigW7du9OjRgx//+McsWLCAsLAwdu7cyd69e+nRo0eD63j33XdZsWIFs2bN8sUpLGTDhg2cccYZ3HzzzRQUFPDaa69x8cUXExHRNl/hASsEzrl7gHsAzGwycFe9IgAwG7gaWAhcAvzbNVYqj9Gg9AQWbf5GnRGRUJSY4d8t1MDyY3DppZcya9Ys9uzZw7Rp03jxxRcpKChgyZIlREZGkp2d3ejhnc45HnvsMc4888xvPHfVVVfxwgsv8PLLL/PMM88cU8662v08AjN7wMzO9z98Gkg2s43AHcDdgXzvAWnx7Cosp6hcRw6JhLwp90Jkl68vi+ziW34Mpk2bxssvv8ysWbO49NJLKSwsJC0tjcjISObNm8e2bUe9CCgAZ555Jk888QRVVb7vqfXr11NSUgLANddcwx//+EcAhg0bdkw562qXM4udc/OB+f7799ZZXg5c2h4Z4KsjhzYVlDAmM6m93lZEOqJRl/n+ff8B3+6gxAxfETiyvJWGDx9OUVERvXv3pmfPnlx55ZWcd955jBw5kpycHIYMGdLo63/4wx+ydetWxo0bh3OO1NTULweJ09PTGTp0KBdeeOExZazPArgnJiBycnJca+cj2LKvhFN/P5+HLhnFpTmZbZxMRLy2Zs0ahg4d6nWMgCktLWXkyJEsXbqUxMTEo7Zr6L+DmS1xzuU01D6kLjGR2a0LURE6ckhEgs97773H0KFDueWWWxotAq0RUhediwgPo19KnM4lEJGgM3Xq1CbHF1orpLYIAAamJ2iLQESkjpArBIPS4sk7WEZpZbXXUUQkAIJt3LOttab/IVcIBqb7jxzKL/E4iYi0tZiYGPbv3x+yxeDIfAQxMTEtel1IjREADDhyzaH8IkZmtO2Ai4h4KyMjg7y8PFp7KZrO4MgMZS0RcoWgT3IskeHG+r0aJxDpbCIjI1s0M5f4hNyuocjwMPqmxLExX0cOiYhACBYC8F2SWkcOiYj4hGQhGJAWz/YDpZRX1XgdRUTEcyFZCAalJ+AcbCrQVoGISEgWgiOHkGraShGREC0E2clxhIcZG3TkkIhIaBaCqIgwspNjWa9rDomIhN55BEcMTEtQIeiEdh0qY8m2gyzZdpB1e3yfb0S4ER5mxEVHcNrgNM4Ynk5CTKTHSUU6jtAtBOnxvLt6D4dKK0mKjfI6jrRQdU0ta3YXsW5vERv2FrF+bxFrdhex57BvCsAukeEM6ZlAZFgY5dU11NQ61u4u4q0Vu4n+exhTh6Zz/pheTB6cSnREuMe9EfFWyBaCs0f25E/zNvLEB5u459uddyKLYOCcY8eBMjbvK2ZAWjy9k7pgZt9od6Ckkg/W5zNvbQEfrC+gsMw3lV9UeBj9UuM4sV93xmYmcVyf7r4iEB72jfdZuv0Qs5ftZM6K3by1cjcJMRGcPaInF4zpxYn9kgkP++b7inR2ITVDWX13vLKMOSt3M/+uyfRK6tL0C+SYOOc4WFrF7sIy9hSWs2VfCUu3HyR360Hyiyq+bJccF8XIjET6pcSzr7iCvIOl7DhYRoG/TUp8FJMGpTFpcCrDe3WlT/dYIsJbNtxVXVPLx5v2849lO3nniz2UVNaQlhDNlKHpTBmSxsQBKXSJ0paCdB6NzVAW0oVgx4FSpjz8AReO7cXvLhndJusMdc45iiqqKSiqYPehctbuOczaPUWs3XOYjfnFlFfVfq1976Qu5GR3Iye7OwNS49lYUMzKvEOsyCtk6/4S0rvGkNGtCxlJsWQlx/KtASmM7J1IWBv+ci+rrOH9tXuZs3w3H24ooKSyhuiIMMb3S2ZcVjdGZSQyMiORlPjoNntPkfamQtCIX85ZzTMfb+Gd209hYHpCs19XU+uorK4N6V+NldW1fLGrkKXbfL/qV+0uJP9wBRXVX/+yT02IZkiPBAalJ9A7qQu9kmLokdiF3kldSE3oWF+uFdU1LN5ykPfX7uXDDfvYVFDMkT+RrO6x/OycoZwxvIe3IUVaQYWgEQdKKpn0u3mM75/MU1c1+N8I8O1KmLeugKXbD7Js+yFW7iyksrqWH502gBsn9Scqov2OxP1sywEembuexVsPcNnxmfzo1AEB37W1bX8JLy3azq7CcvYeLif/cDm7DpVTWeP70s/qHsvozCR6JsaQGh9NakI0aQnRDOqRENS/pIvKq1i16zAr8wp5/fOdrNl9mMtPyOTn5w4jNipkh9gkCKkQNOFP/97A799dz6wbJ5CT3b3BNnfOXM5rS/OICDOG9uzKmMwkDpRU8tbK3QxOT+C3F49kbFa3Ns1VX+7WAzzy3no+3riflPhoTuqfzNtf7MYwLj8hk2u/1Y/oyDBKKqopqajB4RiUnkBMZOu3WmprHc9+spXfvbOW2lrolRRDWtcY0rvG0CsxhjGZSRzXpxtpXVs2EUYwqqyu5eG565ixYDPZyXH8cdoYRmcmeR1LpFlUCJpQWlnNpIfmk9U9lleuH/+NgcdZS/K469Xl3DS5P7dNGfi1L9b31+zlZ298wZ7D5Vw7sS/3nD20zY48KSyrYuGmfXy4wXfbfqCUlPgobpzUnytP7EOXqHDyDpby+LxNvJq7g+rab36WdQtX35Q4dheWsWVfKVv3l5B/uJy46AgSYiJIiImkW2wUw3v52o7KSORweTX/NWs5i7ce5NTBqfzmolH0SOz8X/hN+WTTPu6cuZyCogruOXsoP5iY3eBRTiIdiSeFwMxigAVANL7DVGc5535Rr00W8ByQBIQDdzvn/tnYegNRCOCrL/vTh6Xz2OVjv/yy35hfzHmPfcTozERe/OH4Br/ki8qr+M3ba3lp0XYuPyGL//edEcf0xVBb6/jj+xt4fN5GamodcVHhTOifzOTBaVw8LqPBcYkdB0p5b81eoiPCiYsOJzYqguqaWlbuLGTZDt/ga3FFNdERYfRJjiU7OY4eiTGUVdZQVF5NcUU1+UXlbMwv5kg9CQ8zYqPC+cV5w7l4XG992dVRWFrFXbOWM3f1Xs4Z1ZMHLx5FfLR2FUnH5VUhMCDOOVdsZpHAR8BtzrlP67SZAXzunHvCzIYB/3TOZTe23kAVAoDnPtnKfW+u4vjs7vz56hyiwsO48PGPyS+q4O3bTia9id0fD72zlsfnbeLmyf35r7OGtCpDcUU1d7yyjHdX7+XCMb244sQ+jM1K+sYx8S1VU+s4UFJJclxUo0fcFFdU88XOQpbvOMT+kkp+MLGvtgKOorbWMX3BZh56Zy19U+KY/r3jvpwKVaSjaawQBOwnjPNVmCNXdYv03+pXHQd09d9PBHYFKk9zXH1SNkmxkdw5cznTpn/K4PR41u4p4tnvH99kEQC464zBHCyt4v/mb6JbbBTXndLvqG0rqmtYv6eY9MRoUuOjMTO27S/huudz2VRQwi/OG8Y1J7XdLofwMGvWETrx0RGM75fM+H7JbfK+nVlYmHHT5P6Mzkzk1r99zvl/+phHvzuWqcPSvY4m0iIBHSMws3BgCTAAeNw599N6z/cE3gW6AXHAVOfckgbWcz1wPUBWVtZx27ZtC1hmgA/WF3DjX5dQVlXDjZP6c/e3m//rvqbWcevfPuetlbv57UUjmXZ85te+zKtranltaR6Pvr+RnYfKAIiJDCOreyx7CssxMx6/YhzfGpjS5v2SwNlTWM71f83li52F3HvuMK6ZqHlzpWPxfLDYzJKAvwO3OOe+qLP8Dn+Gh81sAvA0MMI5V9vwmgK7a6iu5TsO8f7afG45bUCLd8tUVNfww+dy+XDDPpLjohjfP5mT+icTHRHO4/M2smVfCaMzk7h6Qh+KK6rZvr+U7QdKqXWOn587jD7JcQHqlQRSaWU1t728jLmr9/L9idn87JxhumSFdBieFwJ/iHuBUufc7+ssWwWc5Zzb4X+8GRjvnMs/2nraqxAcq/KqGt5cvouFm/bzyab9X14MbUiPBO48YzBTh6Zp8LUTqql1/PqtNfzl4y3fOPBAxEuejBGYWSpQ5Zw7ZGZdgNOBB+s12w5MAZ41s6FADFAQqEztKSYynEtzMrk0JxPnHFv3l7L3cDknZHdv08sjSMcSHmbce94w+iTH8ovZq7jr1eU8+t2x+sylQwvk8W49gef84wRhwEzn3BwzewDIdc7NBu4EnjKzH+MbOL7GBduJDc1gZvRNiaNvinb5hIqrT8qmtLKGB/+1ln4pcdxxxmCvI4kcVSCPGloBjG1g+b117q8GJgYqg4iXbpzUj637Snj03xvpkxzHxcdleB1JpEE6A0YkQMyMX144gh0HS7n79RVkdOvCiTosVzqgkJyzWKS9REWE8cSVx5HZPZYbXlhC3sFSryOJfIMKgUiAJcZG8perj6eyupafvfEFnXAYTIKcCoFIO8hOieOuMwYzf10Bs5d7egK9yDeoEIi0k6tPymZ0ZhL3v7maAyWVXscR+ZIKgUg7CQ8zHrx4JIfLqvjVW6u9jiPyJRUCkXY0pEdXbpzUn9eX7uTDDZ3i3EnpBFQIRNrZj04bQL+UOP777yspq6zxOo6ICoFIe4uJDOfX3xnJjgNlPL9wq9dxRFQIRLwwoX8yJw9MYfqCzZRWVnsdR0KcCoGIR26fOogDJZX8dWFg59cQaYoKgYhHjuvTjVMGpTJ9wWZKKrRVIN5RIRDx0G1TBvq2Cj7VVoF4R4VAxENHtgpmaKtAPKRCIOKx26f6tgqe11iBeESFQMRj47K6MWlQKjMWbNJWgXhChUCkA7h1ygAOllbx+uc7vY4iIUiFQKQDGJfVjeG9uvLip9t0mWppdyoEIh2AmXHFiVms3VPE5zsOeR1HQowKgUgHccGY3sRFhfPip9u9jiIhRoVApIOIj47gwrG9mbNiF4WlVV7HkRCiQiDSgVxxYhYV1bW8tjTP6ygSQlQIRDqQ4b0SGZOZxIuLNGgs7SdghcDMYszsMzNbbmarzOz+o7S7zMxW+9u8FKg8IsHiyhOz2FRQwqItB7yOIiEikFsEFcBpzrnRwBjgLDMbX7eBmQ0E7gEmOueGA7cHMI9IUDh3VC+6xkTw0iINGkv7CFghcD7F/oeR/lv9bd3rgMedcwf9r8kPVB6RYNElKpyLxmXw9he72XmozOs4EgICOkZgZuFmtgzIB+Y65xbVazIIGGRmH5vZp2Z21lHWc72Z5ZpZbkGB5nmVzu/qk7KJCg/juzMWsm1/iddxpJMLaCFwztU458YAGcAJZjaiXpMIYCAwGbgceMrMkhpYzwznXI5zLic1NTWQkUU6hL4pcbx03XiKy6u55MmFrN1z2OtI0om1y1FDzrlDwDyg/i/+PGC2c67KObcFWI+vMIiEvNGZScy8YQLhZlz25EKWbDvodSTppAJ51FDqkV/3ZtYFOB1YW6/ZG/i2BjCzFHy7ijYHKpNIsBmYnsCrN06ge1wU//HnRWwuKG76RSItFMgtgp7APDNbASzGN0Ywx8weMLPz/W3eAfab2Wp8Www/cc7tD2AmkaCT2T2Wv10/nuraWh1JJAFhwXbSSk5OjsvNzfU6hki7u/GvS8jddoCF90whMlzngkrLmNkS51xOQ8/p/yaRIHFpTgb7iiuZt1ZHWUvbUiEQCRKTBqWSmhDNq0t0HSJpWyoEIkEiIjyMi8b25t9r8ykoqvA6jnQiKgQiQeTSnAxqah1vaEpLaUMqBCJBZEBaAmOzknh1yQ5dnVTajAqBSJC59LhM1u8tZkVeoddRpJNQIRAJMueO7klMZBivLtnhdRTpJFQIRIJM15hIvj2iJ/9Ytovyqhqv40gnoEIgEoQuzcmgqLyaf67c7XUU6QRUCESC0IR+yfRLjeP5hdu8jiKdgAqBSBAyM64a34dlOw6xfMchr+NIkFMhEAlSFx+XQVxUuLYK5JipEIgEqYSYSC4al8GbK3ZxoKTS6zgSxFQIRILY9yb0obK6llcW61BSaT0VApEgNig9gQn9knnh023U1OpMY2kdFQKRIHfVhD4cd3gulb8fBvclwSMjYMVMr2NJEInwOoCIHJszahYwOeppupT6r0hauAPevNV3f9Rl3gWToKEtApEgFz7vl3Sh3mWpq8rg/Qe8CSRBp1mFwMzizCzMf3+QmZ1vZpGBjSYizVJ4lIlqjrZcpJ7mbhEsAGLMrDfwLvA94NlAhRKRFkjMaNlykXqaWwjMOVcKXAT8n3PuUmB44GKJSLNNuRciu3x9WWQX33KRZmh2ITCzCcCVwFv+ZeGBiSQiLTLqMjjvUUjMxGHsdCkUTn1YA8XSbM0tBLcD9wB/d86tMrN+wLyApRKRlhl1Gfz4C7b9aCcnVz7K4/vHeZ1IgkizCoFz7gPn3PnOuQf9g8b7nHO3NvYaM4sxs8/MbLmZrTKz+xtpe7GZOTPLaWF+EakjOyWOc0f14oVPt3FQl52QZmruUUMvmVlXM4sDvgBWm9lPmnhZBXCac240MAY4y8zGN7DuBOA2YFGLkotIg/7z1AGUVtbwzCdbvY4iQaK5u4aGOecOAxcCbwN98R05dFTOp9j/MNJ/a+gc+F8CDwLlzcwiIo0Y3COB04el8+zHWygqr/I6jgSB5haCSP95AxcCs51zVTT8pf41ZhZuZsuAfGCuc25RvefHAZnOubcaer2ItM6PTh3A4fJqXaJamqW5hWA6sBWIAxaYWR/gcFMvcs7VOOfGABnACWY24shz/rGGPwB3NrUeM7vezHLNLLegoKCZkUVC1+jMJE4bksaMBZs5rK0CaUJzB4sfdc71ds6d7d/lsw04tblv4pw7hO8oo7PqLE4ARgDzzWwrMB6Y3dCAsXNuhnMuxzmXk5qa2ty3FQlpP546iMKyKp79eKvXUaSDa+5gcaKZ/eHIr3Izexjf1kFjr0k1syT//S7A6cDaI8875wqdcynOuWznXDbwKXC+cy63lX0RkTpGZiRy+rB0nvpwM4Vl2iqQo2vurqG/AEXAZf7bYeCZJl7TE5hnZiuAxfjGCOaY2QNmdn5rA4tI890+dSBF5dU8/dEWr6NIB9bcy1D3d85dXOfx/f5B4KNyzq0AxjawvMHz3p1zk5uZRUSaaXivRM4a3oNnPtrCDyZmkxQb5XUk6YCau0VQZmbfOvLAzCYCZYGJJCJt6fbTB1JUUc2fP9RWgTSsuYXgRuBxM9vqH9j9E3BDwFKJSJsZ0qMr54zqyTMfb9Ek99Kg5h41tNx/hvAoYJRzbixwWkCTiUibuX3KQEqranjyg01eR5EOqEUzlDnnDvvPMAa4IwB5RCQABqYn8J2xvXnuk63sKdRJ/PJ1xzJVpbVZChEJuB9PHUStc/zv+xu8jiIdzLEUgiYvMSEiHUdm91iuOCGLmbk72FxQ3PQLJGQ0WgjMrMjMDjdwKwJ6tVNGEWkjPzptIFHhYfxh7nqvo0gH0mghcM4lOOe6NnBLcM419xwEEekgUhOiufZbfZmzYjdf7Cz0Oo50EMeya0hEgtB1p/QjsUskv393nddRpINQIRAJMYldIrlpcn/mrytg0eb9XseRDkCFQCQEXT0hm7SEaB56Zx3O6biPUKdCIBKCukSFc8uUgeRuO8j8dZrjI9SpEIiEqGk5mWR1j+V376yjtlZbBaFMhUAkREVFhHHH6YNYs/swb63c7XUc8ZAKgUgIO390L4b0SOAPc9dTVVPrdRzxiAqBSAgLCzPuPGMwW/aVMGtJntdxxCMqBCIhburQNMZlJfG/722gvKrG6zjiARUCkRBnZtx15mD2HC5nZu4Or+OIB1QIRIQJ/ZIZl5XEjAWbqdZYQchRIRARzIwbJ/Un72CZjiAKQSoEIgLA1KHpDEiL58kPNuts4xCjQiAigO8IoutP6cea3YdZsGGf13GkHakQiMiXLhzTmx5dY3hyvuY2DiUqBCLypaiIMK79Vl8Wbt7P8h2HvI4j7SRghcDMYszsMzNbbmarzOz+BtrcYWarzWyFmb1vZn0ClUdEmufyE7PoGhPBkx9oqyBUBHKLoAI4zTk3GhgDnGVm4+u1+RzIcc6NAmYBvwtgHhFphvjoCL43oQ//WrVHcxuHiIAVAudz5P+iSP/N1WszzzlX6n/4KZARqDwi0nzfn9iXqPAwpn+w2eso0g4COkZgZuFmtgzIB+Y65xY10vxa4O2jrOd6M8s1s9yCAl07XSTQUuKjmXZ8Jq9/nsfuwjKv40iABbQQOOdqnHNj8P3SP8HMRjTUzsz+A8gBHjrKemY453KcczmpqakByysiX7n+lH44B08t2OJ1FAmwdjlqyDl3CJgHnFX/OTObCvwPcL5zrqI98ohI0zK6xXLBmN787bPtHCip9DqOBFAgjxpKNbMk//0uwOnA2nptxgLT8RWB/EBlEZHWuWlyP8qra3j2Y20VdGaB3CLoCcwzsxXAYnxjBHPM7AEzO9/f5iEgHnjVzJaZ2ewA5hGRFhqQlsCZw3rw7CdbKSqv8jqOBEhEoFbsnFsBjG1g+b117k8N1PuLSNu4+dT+/GvVHl5atJ0bJvX3Oo4EgM4sFpFGjcpI4uSBKfz5oy2auKaTUiEQkSbdPHkABUUVPL9wq9dRJABUCESkSRP6J3PakDQee38jBUU6uK+zUSEQkWb5n3OGUlZVw8PvrvM6irQxFQIRaZb+qfFcc1I2r+Tu4IudhV7HkTakQiAizXbLlIF0j43igTdXaxazTkSFQESaLbFLJHedOZjPth7Q3MadiAqBiLTIZTmZDO3Zld/8c60OJ+0kVAhEpEXCw4xfnDeMnYfKeOHTbV7HkTagQiAiLTa+XzIn9u3O0x9tobK61us4coxUCESkVW4+dQC7C8t5Y9lOr6PIMVIhEJFWOWVgCsN7deXJDzZRU6sjiIKZCoGItIqZcdPk/mwuKGHu6j1ex5FjoEIgIq327RE9yU6O5f/mb9J5BUFMhUBEWi08zLhhUn9W5BXyyab9XseRVlIhEJFjctG43qQlRPPE/E1eR5FWUiEQkWMSHRHOD0/uy0cb9/H59oNex5FWUCEQkWN2xYl9SI6L4rdvr9VYQRBSIRCRYxYfHcHtUweyaMsB/r023+s40kIqBCLSJr57QhZ9U+L47dtrqa7R2cbBRIVARNpEZHgYPz1rMBvyi5m1JM/rONICKgQi0mbOHN6DcVlJ/GHuekorq72OI82kQiAibcbM+O+zh5JfVMGfP9zidRxppoAVAjOLMbPPzGy5ma0ys/sbaBNtZq+Y2UYzW2Rm2YHKIyLtIye7O2cOT2f6B5vIP1zudRxphkBuEVQApznnRgNjgLPMbHy9NtcCB51zA4BHgAcDmEdE2slPzxpCda3jR3/7nCoNHHd4ASsEzqfY/zDSf6t/gPEFwHP++7OAKWZmgcokIu2jX2o8D148is+2HOCXc1Z7HUeaENAxAjMLN7NlQD4w1zm3qF6T3sAOAOdcNVAIJDewnuvNLNfMcgsKCgIZWUTayIVje3PdyX15fuE2Xlm83es40oiAFgLnXI1zbgyQAZxgZiNauZ4Zzrkc51xOampqm2YUkcD56VlDOHlgCj9/YxVLdfmJDqtdjhpyzh0C5gFn1XtqJ5AJYGYRQCKgSxiKdBIR4WE8dvlYeiTGcONfl5BfpMHjjiiQRw2lmlmS/34X4HRgbb1ms4Gr/fcvAf7tdKESkU4lKTaKGVcdx6GyKn791hqv40gDArlF0BOYZ2YrgMX4xgjmmNkDZna+v83TQLKZbQTuAO4OYB4R8ciQHl25cVJ//rFsFws1b0GHY8H2AzwnJ8fl5uZ6HUNEWqi8qobTH/mAmIhw/nnbyUSG63zW9mRmS5xzOQ09p09CRNpFTGQ49503nA35xfzlI5113JGoEIhIu5kyNJ2pQ9P43/c3sLuwzOs44qdCICLt6hfnDaem1vGrORo47ihUCESkXWV2j+U/Tx3AWyt389GGfV7HEVQIRMQD15/Sj6zusdz/5ipdi6gDUCEQkXYXExnOz84Zyob8Yl74dJvXcUKeCoGIeOL0YemcPDCFR+auZ39xhddxQpoKgYh4wsy499xhlFTW8PDc9V7HCWkqBCLimYHpCVw1oQ9/+2w7q3YVeh0nZKkQiIinbp86iG6xUdw/ezXBdqWDzkKFQEQ8ldglkrvOGMxnWw/w/EINHHtBhUBEPDft+EymDEnjgTmr+WC9Jp9qyMGSSorKqwKybl10TkQ6hOKKai554hN2Hizj9ZtPYmB6gteRPFFdU8v6vcWsyDvE2j1FbMgvYv3eYgqKKvjtRSP57glZrVpvYxedizimxCIibSQ+OoKnrzmeC/70MT94bjFv3DyR5Phor2O1Gecc2w+UsnjrQXK3HmB5XiGR4UZSbBTdYiOJi45gY34xK/MKKauqASA2KpyBafFMGpTKoPR4juvTLSDZtEUgIh3Ksh2HmDZ9ISN6J/LiD08kJjLc60gt5pxj1a7DrNpVyLo9xazfW8TaPYfZV1wJQNeYCMZkdcOAQ6WVHCyt4nB5FX2S4xibmcSYzCRGZybRp3ssYWHWJpm0RSAiQWNMZhIPXzaaH730OQ+9s46fnzvM60jNtvdwOa8v3cmrS3awuaAEgJjIMAamJTBpUBpjs5I4Prs7A9Pi2+wLvi2oEIhIh3PuqF58unk/f/l4C6cPS2d8v2SvIzWooKiCL3YWsiKvkNxtB/h44z5qHRyf3Y0bTunHiX2TyeweS3gH+tJviAqBiHRI/332UD7csI+7Xl3O27edTEJMpNeRKK+qYeGm/cxds5f5a/PZVVgOgBn0S4njpsn9ueS4TPqmxHmctGVUCESkQ4qNiuDhS0dz2fSF/GrOGh68ZFTA37Oyupa1ew6zbMchVu86TFlVDTW1DuegpLKaz7YcoLSyhtiocE4ZmMoPvtWNURlJDOvVlfjo4P06Dd7kItLp5WR354ZJ/Xli/ibOGJ7OlKHpbbp+5xzr9hbx3uq9/HttPl/sPEyl/7LYyXFRJMREEGZGWJgREWZcOLY3pw9LZ0K/5KAcxD4aFQIR6dBunzqQeWvz+elrK3n7tiRSE479kNLK6loeeW89c1bsYscB35SZozMSuWZiNqMzkhiTlUSvxBjMOva+/baiQiAiHVp0RDh/uGwMFz3xMdOmL+S5H5xAZvfYY1rn8wu38sT8TUwenMrNkwcwZUgaaV1j2ihx8NElJkSkwxvWqysvXHsi+4oruOTJT1i3p6jV69pXXMH/vreByYNTefb7J3D5CVkhXQQggIXAzDLNbJ6ZrTazVWZ2WwNtEs3sTTNb7m/z/UDlEZHglpPdnZk3TsA5uGz6QpZsO9Cq9Tz87jrKqmr42TnBc35CoAVy11A1cKdzbqmZJQBLzGyuc251nTb/Cax2zp1nZqnAOjN70TlXGcBcIhKkhvToyms3ncT3nl7EFU8tYlivriR2iSSpSyRJsVFkdOtCv9Q4spPjyOweS2T413/rrtpVyMuLd/CDiX0ZkBbvUS86noAVAufcbmC3/36Rma0BegN1C4EDEsw3IhMPHMBXQEREGpTZPZZZN53EQ/9ax85DZewvrmRzQQkHSioprvjq6yMqPIwrTszix1MHkRgbiXOO+99cTbfYKG6dMtDDHnQ87TJYbGbZwFhgUb2n/gTMBnYBCcA051xte2QSkeCVEh/9jfMKnHMcLK1iy75ituwr5bMt+3l+4VZmL9/FT84cTFx0BJ9tOcD/+85IErt4f3JaRxLwi86ZWTzwAfBr59zr9Z67BJgI3AH0B+YCo51zh+u1ux64HiArK+u4bds0eYWING3VrkLun72az7YewMy3a2nOLd/q8Jd8CITGLjoX0KOGzCwSeA14sX4R8Ps+8Lrz2QhsAYbUb+Scm+Gcy3HO5aSmpgYysoh0IsN7JfLKDeN59PKxjM1M4tffGRGSRaApAds15N/v/zSwxjn3h6M02w5MAT40s3RgMLA5UJlEJPSYGeeP7sX5o3t5HaXDCuQYwUTge8BKM1vmX/bfQBaAc+5J4JfAs2a2EjDgp865fQHMJCIi9QTyqKGP8H25N9ZmF3BGoDKIiEjTdGaxiEiIUyEQEQlxKgQiIiFOhUBEJMSpEIiIhDgVAhGREBfwS0y0NTMrBDbUWZQIFDbwuO7yI/dTgNaep1D/fVrSpqHlR8vd0OP6fVI/jq0fTeVs6nFb9qOpnE0935b9gMB+Ji3pR/1lnaUf9R+3Zz/6OOcavjSDcy6obsCM5jyuu7zOsty2et+WtGloeXP70VCf1I9j60dLcweyH83pS3v1I9CfSUv6cbSswd6PxvrV3v2oewvGXUNvNvPxm420aYv3bUmbhpY3tx9176sfjWdpSZuW5K7/uC370Zz1hGI/6i/rLP2o/9jLfnwp6HYNHQszy3VHufpeMFE/OpbO0g/oPH1RP1omGLcIjsUMrwO0EfWjY+ks/YDO0xf1owVCaotARES+KdS2CEREpB4VAhGREKdCICIS4lQI/MzsZDN70sz+bGafeJ2ntcwszMx+bWaPmdnVXudpLTObbGYf+j+TyV7nORZmFmdmuWZ2rtdZWsvMhvo/i1lmdpPXeVrLzC40s6fM7BUzC9q5UMysn5k9bWaz2mJ9naIQmNlfzCzfzL6ot/wsM1tnZhvN7O7G1uGc+9A5dyMwB3gukHmPpi36AVwAZABVQF6gsjamjfrhgGIghuDuB8BPgZmBSdm0Nvr7WOP/+7gM3+yD7a6N+vGGc+464EZgWiDzHk0b9WOzc+7aNgvV2rPWOtINOAUYB3xRZ1k4sAnoB0QBy4FhwEh8X/Z1b2l1XjcTSAjWfgB3Azf4XzsriPsR5n9dOvBiEPfjdOC7wDXAucHaD/9rzgfeBq4I5n74X/cwMK4T9KNN/sYDOWdxu3HOLTCz7HqLTwA2Ouc2A5jZy8AFzrnfAA1uoptZFlDonCsKZN6jaYt+mFkeUOl/WBPAuEfVVp+H30EgOiBBm9BGn8dkIA7fH3WZmf3TOVcbyNz1tdXn4ZybDcw2s7eAlwIYuUFt9HkY8Fvgbefc0gBHblAb/320iU5RCI6iN7CjzuM84MQmXnMt8EzAErVOS/vxOvCYmZ0MLAhksBZqUT/M7CLgTCAJ+FNAk7VMi/rhnPsfADO7BtjX3kWgES39PCYDF+Eryv8MZLAWaunfxy3AVCDRzAY4554MZLgWaOnnkQz8GhhrZvf4C0ardeZC0GLOuV94neFYOedK8RW0oOacex1fUesUnHPPep3hWDjn5gPzPY5xzJxzjwKPep3jWDnn9uMb52gTnWKw+Ch2Apl1Hmf4lwUb9aNjUT86FvWjDXTmQrAYGGhmfc0sCt+A3WyPM7WG+tGxqB8di/rRFrwYNQ/AKPzfgN18dcjktf7lZwPr8Y3G/4/XOdUP9UP9UD86Yj900TkRkRDXmXcNiYhIM6gQiIiEOBUCEZEQp0IgIhLiVAhEREKcCoGISIhTIZBOwcyK2/n92mTOCv+8C4VmtszM1prZ75vxmgvNbFhbvL8IqBCINMjMGr0Ol3PupDZ8uw+dc2OAscC5ZtbU9f4vxHc1U5E2oUIgnZaZ9Tezf5nZEvPNdjbEv/w8M1tkZp+b2Xtmlu5ffp+Z/dXMPgb+6n/8FzObb2abzezWOusu9v872f/8LP8v+hf9lzrGzM72L1tiZo+a2ZzG8jrnyoBl+K5EiZldZ2aLzWy5mb1mZrFmdhK+eQEe8m9F9D9aP0WaS4VAOrMZwC3OueOAu4D/8y//CBjvnBsLvAz8V53XDAOmOucu9z8egu9y2CcAvzCzyAbeZyxwu/+1/YCJZhYDTAe+7X//1KbCmlk3YCBfXT78defc8c650cAafJci+ATfNWh+4pwb45zb1Eg/RZpFl6GWTsnM4oGTgFf9P9DhqwluMoBXzKwnvtmgttR56Wz/L/Mj3nLOVQAVZpaPb8a0+lNnfuacy/O/7zIgG980m5udc0fW/Tfg+qPEPdnMluMrAn90zu3xLx9hZr/CNydDPPBOC/sp0iwqBNJZhQGH/Pve63sM+INzbrZ/wpX76jxXUq9tRZ37NTT8N9OcNo350Dl3rpn1BT41s5nOuWXAs8CFzrnl/oltJjfw2sb6KdIs2jUknZJz7jCwxcwuBd8UhWY22v90Il9d6/3qAEVYB/SrMyVhkxOl+7cefotvsnuABGC3f3fUlXWaFvmfa6qfIs2iQiCdRayZ5dW53YHvy/Na/26XVcAF/rb34duVsgTYF4gw/t1LNwP/8r9PEVDYjJc+CZziLyA/BxYBHwNr67R5GfiJf7C7P0fvp0iz6DLUIgFiZvHOuWL/UUSPAxucc494nUukPm0RiATOdf7B41X4dkdN9zaOSMO0RSAiEuK0RSAiEuJUCEREQpwKgYhIiFMhEBEJcSoEIiIhToVARCTE/X++4e/3/+b6DAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c8e1969-ba87-43b3-947d-f046208b77e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>COCOMetric</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "loss() missing 1 required positional argument: 'img_metas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5f8afe75573d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfine_tune\u001b[0;34m(self, epochs, base_lr, freeze_epochs, lr_mult, pct_start, div, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;34m\"Fine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreeze_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mbase_lr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    114\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    115\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/icevision/models/mmdet/fastai/callbacks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data, optimizer)\u001b[0m\n\u001b[1;32m    246\u001b[0m                   \u001b[0maveraging\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/mmcv/mmcv/runner/fp16_utils.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                                 'method of nn.Module')\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fp16_enabled'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# get the arg spec of the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/mmdet/models/detectors/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/mmdet/models/detectors/single_stage.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSingleStageDetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         losses = self.bbox_head.forward_train(x, img_metas, gt_bboxes,\n\u001b[0m\u001b[1;32m     84\u001b[0m                                               gt_labels, gt_bboxes_ignore)\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sahi/lib/python3.9/site-packages/mmdet/models/dense_heads/base_dense_head.py\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, x, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore, proposal_cfg, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mloss_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgt_bboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bboxes_ignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgt_bboxes_ignore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproposal_cfg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/mmcv/mmcv/runner/fp16_utils.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m                                 'method of nn.Module')\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fp16_enabled'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mold_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;31m# get the arg spec of the decorated method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0margs_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: loss() missing 1 required positional argument: 'img_metas'"
     ]
    }
   ],
   "source": [
    "learn.fine_tune(20, 3e-4, freeze_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e42356-aea7-48d6-983b-0b3bc76a0f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sahi] *",
   "language": "python",
   "name": "conda-env-sahi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
