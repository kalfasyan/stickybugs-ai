{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755f6f56-624e-4a07-9d63-6bbda1086975",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6c0220-6762-4f0d-a29b-9dddf05fce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available workers: 8\n"
     ]
    }
   ],
   "source": [
    "from datasets import InsectImgDataset\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "setting = 'photobox'\n",
    "if setting == 'photobox':\n",
    "    ext = '.png'\n",
    "elif setting == 'fuji':\n",
    "    ext = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3cc90d-2b00-4218-9abf-3c8b87561261",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = InsectImgDataset(ext=ext, setting=setting, directory=DATA_DIR)\n",
    "# dfs.extract_df_info()\n",
    "# df = dfs.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6d718-bbd3-47e8-856c-edf79c2503b3",
   "metadata": {},
   "source": [
    "# Creating train,val,test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932df95-bc04-4f37-870d-f4ba816189eb",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff6e8f1-2969-405c-b6ac-f01042a9a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pre = pd.read_parquet(f\"{SAVE_DIR}/df_preparation_{setting}.parquet\")\n",
    "# df = pd.merge(df,df_pre, on=['filename','label','platename','imgname','date','year','plate_idx','location','xtra'])\n",
    "# df = df[df.knn_outlier==0]\n",
    "# df = df[df.nb_contours>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f519ea27-baa4-472f-bc75-6339cc5a45fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(f\"{SAVE_DIR}/df_train_{setting}.parquet\")\n",
    "df_val = pd.read_parquet(f\"{SAVE_DIR}/df_val_{setting}.parquet\")\n",
    "df_test = pd.read_parquet(f\"{SAVE_DIR}/df_test_{setting}.parquet\")\n",
    "\n",
    "topclasses = df_train['txt_label'].unique().tolist()\n",
    "\n",
    "# plt.figure(figsize=(20,5))\n",
    "# plt.subplot(1,3,1);df_train.txt_label.value_counts().plot(kind='barh');plt.title(f'train, {df_train.shape[0]}')\n",
    "# plt.subplot(1,3,2);df_val.txt_label.value_counts().plot(kind='barh');plt.title(f'val, {df_val.shape[0]}')\n",
    "# plt.subplot(1,3,3);df_test.txt_label.value_counts().plot(kind='barh');plt.title(f'test, {df_test.shape[0]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a5abde9-e2bc-4370-9648-95490d3ef4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(set(df_train.filename.tolist()).intersection(df_test.filename.tolist())) == 0\n",
    "# assert len(set(df_train.filename.tolist()).intersection(df_val.filename.tolist())) == 0\n",
    "\n",
    "# # df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fa2580-09ed-4b27-845b-1ea999b2083c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating Pytorch Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a057aa14-f825-4314-a3f3-d0ad8c3f141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_list_train = [\n",
    "#     A.SmallestMaxSize(max_size=150),\n",
    "#     A.Resize(height=150,width=150,p=1),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225], p=1, always_apply=True),\n",
    "    A.ShiftScaleRotate(shift_limit=0.01,rotate_limit=45, scale_limit=0, p=.5),\n",
    "    A.Rotate(limit=90, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    # A.RandomGamma(p=0.5),\n",
    "     A.RandomBrightnessContrast(p=0.2),\n",
    "     A.GaussianBlur(blur_limit=(3,3), p=0.1)\n",
    "]\n",
    "\n",
    "transforms_list_test = [\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                p=1, \n",
    "                always_apply=True)\n",
    "]\n",
    "\n",
    "train_dataset = InsectImgDataset(df=df_train.reset_index(drop=True), transform=A.Compose(transforms_list_train))\n",
    "valid_dataset = InsectImgDataset(df=df_val.reset_index(drop=True), transform=A.Compose(transforms_list_test))\n",
    "test_dataset = InsectImgDataset(df=df_test.reset_index(drop=True), transform=A.Compose(transforms_list_test))\n",
    "\n",
    "batch_size = 128\n",
    "batch_size_val = 128\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size_val, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size_val, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "\n",
    "# plt.imshow(train_dataset[0][0]); plt.title(f\"Example train image, class:{train_dataset[0][1]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb4185-2165-4489-ba12-ce2a91f2ad9d",
   "metadata": {},
   "source": [
    "# Defining the model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e0f7aab-c933-4d1f-87fe-8bd87c0316c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "057e8840-9fde-4505-915e-4c05eb50de94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: True\n"
     ]
    }
   ],
   "source": [
    "modelname = \"efficientnetb0\"\n",
    "model = model_selector(modelname, pretrained=True)\n",
    "if modelname.startswith(\"dense\"):\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(num_ftrs,len(topclasses))\n",
    "if modelname.startswith(\"resn\"):\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs,len(topclasses))\n",
    "if modelname.startswith(\"efficient\"):\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_ftrs,len(topclasses))\n",
    "    \n",
    "# Choosing whether to train on a gpu\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')# Number of gpus\n",
    "model = model.to('cuda', dtype=torch.float)\n",
    "\n",
    "num_epochs = 40\n",
    "\n",
    "class_sample_count = np.unique(df_train.label, return_counts=True)[1]\n",
    "weight = 1. / class_sample_count  \n",
    "criterion = nn.CrossEntropyLoss(weight=torch.Tensor(weight).cuda(), label_smoothing=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd3fb220-8a12-45f6-85c1-a92bbdb88b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=.001)\n",
    "\n",
    "model, optimizer = load_checkpoint(f'{SAVE_DIR}/{modelname}_{setting}_best.pth.tar', model, optimizer)\n",
    "model = model.to('cpu', dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8a50448-a334-4a22-8c70-5de0fd974eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelticks = list({'bl':0,'wswl':1,'sp':2,'t':3,'sw':4,'k':5,'m':6,'c':7,'v':8,'wmv':9,'wrl':10}.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4facbb-e0d8-459a-9d72-1bd1154349c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91372c43-0649-4257-b5f5-22c85ae8b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "def normalize(image):\n",
    "    if image.max() > 1:\n",
    "        image /= 255\n",
    "    image = (image - mean) / std\n",
    "    # in addition, roll the axis so that they suit pytorch\n",
    "    return torch.tensor(image.swapaxes(-1, 1).swapaxes(2, 3)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a689f8-b3d2-4bbe-98fc-f84a6f77dbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6649f170-9cb9-4da4-8955-a97b893723a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.imagenet50()\n",
    "\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff34ec3c-a1ed-4ac9-96ed-3a6989d1fa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 150, 150, 3])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(test_dataloader))\n",
    "X = batch[0].permute(0,2,3,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "87560b56-09ff-4e51-b074-bd269d6c4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_explain = X[[126,127]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "416126ae-af3b-4ac7-b69b-19506f7a41ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'Tensor' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33136/1100574432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_33136/3978810034.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# in addition, roll the axis so that they suit pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'Tensor' and 'list'"
     ]
    }
   ],
   "source": [
    "e = shap.GradientExplainer((model, model.features[-1][2]), normalize(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1279c-c93f-4199-be13-c7af66bc821b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34f59b-20e5-4671-98c2-23ebbdf4fdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('bugai': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd02d839c87abe923a8f6c83e3c07da6b84166f74541505ea2206c85c393cfdbb04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
